{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d08fe1d-250f-45ed-bc5e-bcba8bbb022a",
   "metadata": {},
   "source": [
    "## Analisis de la Encuesta Continua de Hogares 2024\n",
    "\n",
    "- Dataset: https://www4.ine.gub.uy/Anda5/index.php/catalog/767/get-microdata\n",
    "- Diccionario: https://www4.ine.gub.uy/Anda5/index.php/catalog/767/data-dictionary/F4?file_name=ECH_implantacion_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "702f23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTO LIBRERIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fa8ee",
   "metadata": {},
   "source": [
    "## Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "919eed26-0d7d-45f7-84f6-0d51c12a510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGO EL CSV CON PANDAS\n",
    "ech = pd.read_csv(r'C:\\Users\\ut603933\\UM\\tesis\\ECH_implantacion_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "53652266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (55923, 535)\n",
      "\n",
      "Primeras filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>nper</th>\n",
       "      <th>anio</th>\n",
       "      <th>mes</th>\n",
       "      <th>GR</th>\n",
       "      <th>region</th>\n",
       "      <th>REGION_4</th>\n",
       "      <th>dpto</th>\n",
       "      <th>nom_dpto</th>\n",
       "      <th>ccz</th>\n",
       "      <th>barrio</th>\n",
       "      <th>secc</th>\n",
       "      <th>ESTRED13</th>\n",
       "      <th>LOC_AGR_13</th>\n",
       "      <th>NOM_LOC_AGR_13</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5_2</th>\n",
       "      <th>c5_10</th>\n",
       "      <th>c5_11</th>\n",
       "      <th>c5_12</th>\n",
       "      <th>c5_13</th>\n",
       "      <th>c6</th>\n",
       "      <th>c6_1</th>\n",
       "      <th>d8_1</th>\n",
       "      <th>d8_2</th>\n",
       "      <th>d8_3</th>\n",
       "      <th>d8_4</th>\n",
       "      <th>d9</th>\n",
       "      <th>d10</th>\n",
       "      <th>d11</th>\n",
       "      <th>d12</th>\n",
       "      <th>d13</th>\n",
       "      <th>d14</th>\n",
       "      <th>d15</th>\n",
       "      <th>d16</th>\n",
       "      <th>d18</th>\n",
       "      <th>d260</th>\n",
       "      <th>d19</th>\n",
       "      <th>d20</th>\n",
       "      <th>d21_1</th>\n",
       "      <th>d21_2</th>\n",
       "      <th>d21_3</th>\n",
       "      <th>d21_6</th>\n",
       "      <th>d21_4</th>\n",
       "      <th>d21_4_1</th>\n",
       "      <th>d21_5</th>\n",
       "      <th>d21_5_1</th>\n",
       "      <th>d21_20</th>\n",
       "      <th>d21_7</th>\n",
       "      <th>d21_10</th>\n",
       "      <th>d21_11</th>\n",
       "      <th>d21_12</th>\n",
       "      <th>d21_13</th>\n",
       "      <th>d21_14</th>\n",
       "      <th>d21_14_1</th>\n",
       "      <th>d21_15</th>\n",
       "      <th>d21_15_1</th>\n",
       "      <th>d21_15_2</th>\n",
       "      <th>d21_15_3</th>\n",
       "      <th>d21_15_4</th>\n",
       "      <th>d21_15_5</th>\n",
       "      <th>d21_15_6</th>\n",
       "      <th>d21_16</th>\n",
       "      <th>d21_16_1</th>\n",
       "      <th>d21_16_2</th>\n",
       "      <th>d21_21</th>\n",
       "      <th>d21_17</th>\n",
       "      <th>d21_18</th>\n",
       "      <th>d21_18_1</th>\n",
       "      <th>d21_19</th>\n",
       "      <th>d21_19_1</th>\n",
       "      <th>d181</th>\n",
       "      <th>d229</th>\n",
       "      <th>d230</th>\n",
       "      <th>d231</th>\n",
       "      <th>d232</th>\n",
       "      <th>d184</th>\n",
       "      <th>d184_1</th>\n",
       "      <th>d181_b</th>\n",
       "      <th>d184_b</th>\n",
       "      <th>d23</th>\n",
       "      <th>d24</th>\n",
       "      <th>d25</th>\n",
       "      <th>e557</th>\n",
       "      <th>e26</th>\n",
       "      <th>e27</th>\n",
       "      <th>e29_1</th>\n",
       "      <th>e29_2</th>\n",
       "      <th>e29_3</th>\n",
       "      <th>e29_4</th>\n",
       "      <th>e29_5</th>\n",
       "      <th>e29_6</th>\n",
       "      <th>e30</th>\n",
       "      <th>e31</th>\n",
       "      <th>e31_1</th>\n",
       "      <th>e32</th>\n",
       "      <th>e32_1</th>\n",
       "      <th>e33</th>\n",
       "      <th>e34</th>\n",
       "      <th>e35</th>\n",
       "      <th>e36</th>\n",
       "      <th>e185</th>\n",
       "      <th>e186_1</th>\n",
       "      <th>e186_2</th>\n",
       "      <th>e186_3</th>\n",
       "      <th>e186_4</th>\n",
       "      <th>e37</th>\n",
       "      <th>e37_2</th>\n",
       "      <th>e234_2</th>\n",
       "      <th>e38</th>\n",
       "      <th>e38_1</th>\n",
       "      <th>e39</th>\n",
       "      <th>e39_2</th>\n",
       "      <th>e235_2</th>\n",
       "      <th>e236</th>\n",
       "      <th>e236_2</th>\n",
       "      <th>e236_4</th>\n",
       "      <th>e45_cv</th>\n",
       "      <th>e45_1_1_cv</th>\n",
       "      <th>e45_1_1_1_cv</th>\n",
       "      <th>e45_2_1_cv</th>\n",
       "      <th>e45_2_1_1_cv</th>\n",
       "      <th>e45_3_1_cv</th>\n",
       "      <th>e45_3_1_1_cv</th>\n",
       "      <th>e45_4_1_cv</th>\n",
       "      <th>e45_4_1_1_cv</th>\n",
       "      <th>e45_cva</th>\n",
       "      <th>e45_cvb</th>\n",
       "      <th>e46_cv</th>\n",
       "      <th>e47_cv</th>\n",
       "      <th>e47_1_cv</th>\n",
       "      <th>e190</th>\n",
       "      <th>e48</th>\n",
       "      <th>e49</th>\n",
       "      <th>e49a</th>\n",
       "      <th>e579</th>\n",
       "      <th>e583</th>\n",
       "      <th>e581</th>\n",
       "      <th>e579a</th>\n",
       "      <th>e581a</th>\n",
       "      <th>e582</th>\n",
       "      <th>e582_1</th>\n",
       "      <th>e582_2</th>\n",
       "      <th>e582_3</th>\n",
       "      <th>e51_2</th>\n",
       "      <th>e197_1</th>\n",
       "      <th>e51_3</th>\n",
       "      <th>e51_4_a</th>\n",
       "      <th>e201_1a</th>\n",
       "      <th>e51_4_b</th>\n",
       "      <th>e201_1b</th>\n",
       "      <th>e51_5</th>\n",
       "      <th>e201_1c</th>\n",
       "      <th>e51_6</th>\n",
       "      <th>e201_1d</th>\n",
       "      <th>e209_1</th>\n",
       "      <th>e202</th>\n",
       "      <th>e51_6a</th>\n",
       "      <th>e51_6b</th>\n",
       "      <th>e214_1</th>\n",
       "      <th>e51_8</th>\n",
       "      <th>e215_1</th>\n",
       "      <th>e217_1</th>\n",
       "      <th>e51_9</th>\n",
       "      <th>e218_1</th>\n",
       "      <th>e220_1</th>\n",
       "      <th>e51_10</th>\n",
       "      <th>e221_1</th>\n",
       "      <th>e223_1</th>\n",
       "      <th>e51_11</th>\n",
       "      <th>e224_1</th>\n",
       "      <th>e226_1</th>\n",
       "      <th>e559</th>\n",
       "      <th>e559_1</th>\n",
       "      <th>e559_2</th>\n",
       "      <th>e584</th>\n",
       "      <th>e584_1</th>\n",
       "      <th>e59</th>\n",
       "      <th>e246</th>\n",
       "      <th>e247</th>\n",
       "      <th>f269</th>\n",
       "      <th>f270</th>\n",
       "      <th>f271</th>\n",
       "      <th>f272</th>\n",
       "      <th>f273</th>\n",
       "      <th>f69</th>\n",
       "      <th>f69_1</th>\n",
       "      <th>f274</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f70</th>\n",
       "      <th>f71_2</th>\n",
       "      <th>f72_2</th>\n",
       "      <th>f73</th>\n",
       "      <th>f82</th>\n",
       "      <th>f83</th>\n",
       "      <th>f84</th>\n",
       "      <th>f278</th>\n",
       "      <th>f278_a</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280_1</th>\n",
       "      <th>f280_2</th>\n",
       "      <th>f280_3</th>\n",
       "      <th>f281_1</th>\n",
       "      <th>f281_2</th>\n",
       "      <th>f281_3</th>\n",
       "      <th>f281_4</th>\n",
       "      <th>f75</th>\n",
       "      <th>f76_2</th>\n",
       "      <th>f283</th>\n",
       "      <th>f81</th>\n",
       "      <th>f266</th>\n",
       "      <th>f266_1</th>\n",
       "      <th>f266_2</th>\n",
       "      <th>f267</th>\n",
       "      <th>f268</th>\n",
       "      <th>f77</th>\n",
       "      <th>f305</th>\n",
       "      <th>f306</th>\n",
       "      <th>f78</th>\n",
       "      <th>f80</th>\n",
       "      <th>f80_2</th>\n",
       "      <th>f284_1</th>\n",
       "      <th>f284_2</th>\n",
       "      <th>f284_3</th>\n",
       "      <th>f284_4</th>\n",
       "      <th>f284_5</th>\n",
       "      <th>f284_6</th>\n",
       "      <th>f284_7</th>\n",
       "      <th>f285</th>\n",
       "      <th>f286</th>\n",
       "      <th>f287</th>\n",
       "      <th>f85</th>\n",
       "      <th>f307</th>\n",
       "      <th>f308</th>\n",
       "      <th>f288</th>\n",
       "      <th>f289</th>\n",
       "      <th>f290</th>\n",
       "      <th>f291_a</th>\n",
       "      <th>f291_b</th>\n",
       "      <th>f292</th>\n",
       "      <th>f293</th>\n",
       "      <th>f294</th>\n",
       "      <th>f295</th>\n",
       "      <th>f90_2</th>\n",
       "      <th>f91_2</th>\n",
       "      <th>f92</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f94_2</th>\n",
       "      <th>f296_1</th>\n",
       "      <th>f296_2</th>\n",
       "      <th>f296_3</th>\n",
       "      <th>f296_4</th>\n",
       "      <th>f296_5</th>\n",
       "      <th>f296_6</th>\n",
       "      <th>f296_7</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>f101</th>\n",
       "      <th>f102</th>\n",
       "      <th>f103</th>\n",
       "      <th>f297</th>\n",
       "      <th>f298</th>\n",
       "      <th>f104</th>\n",
       "      <th>f299</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f300</th>\n",
       "      <th>f108</th>\n",
       "      <th>f301</th>\n",
       "      <th>f106</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118_1</th>\n",
       "      <th>f118_2</th>\n",
       "      <th>f122</th>\n",
       "      <th>f119_2</th>\n",
       "      <th>f120_2</th>\n",
       "      <th>f121</th>\n",
       "      <th>f123</th>\n",
       "      <th>f124_1</th>\n",
       "      <th>f124_2</th>\n",
       "      <th>f124_3</th>\n",
       "      <th>f124_5</th>\n",
       "      <th>f125</th>\n",
       "      <th>g_id_1</th>\n",
       "      <th>g_id_2</th>\n",
       "      <th>g_id_3</th>\n",
       "      <th>g_id_1a</th>\n",
       "      <th>g_id_2a</th>\n",
       "      <th>g_id_3a</th>\n",
       "      <th>g126_1</th>\n",
       "      <th>g126_2</th>\n",
       "      <th>g126_3</th>\n",
       "      <th>g126_4</th>\n",
       "      <th>g126_5</th>\n",
       "      <th>g126_6</th>\n",
       "      <th>g126_7</th>\n",
       "      <th>g126_8</th>\n",
       "      <th>g250_1</th>\n",
       "      <th>g250_2</th>\n",
       "      <th>g250_3</th>\n",
       "      <th>g250_4</th>\n",
       "      <th>g250_5</th>\n",
       "      <th>g127</th>\n",
       "      <th>g127_1</th>\n",
       "      <th>g127_2</th>\n",
       "      <th>g127_3</th>\n",
       "      <th>g128</th>\n",
       "      <th>g128_1</th>\n",
       "      <th>g129</th>\n",
       "      <th>g129_1</th>\n",
       "      <th>g129_2</th>\n",
       "      <th>g130</th>\n",
       "      <th>g130_1</th>\n",
       "      <th>g131</th>\n",
       "      <th>g131_1</th>\n",
       "      <th>g132</th>\n",
       "      <th>g132_1</th>\n",
       "      <th>g132_2</th>\n",
       "      <th>g132_3</th>\n",
       "      <th>g133</th>\n",
       "      <th>g133_1</th>\n",
       "      <th>g133_2</th>\n",
       "      <th>g_st_1</th>\n",
       "      <th>g134_1</th>\n",
       "      <th>g134_2</th>\n",
       "      <th>g134_3</th>\n",
       "      <th>g134_4</th>\n",
       "      <th>g134_5</th>\n",
       "      <th>g134_6</th>\n",
       "      <th>g134_7</th>\n",
       "      <th>g134_8</th>\n",
       "      <th>g251_1</th>\n",
       "      <th>g251_2</th>\n",
       "      <th>g251_3</th>\n",
       "      <th>g251_4</th>\n",
       "      <th>g251_5</th>\n",
       "      <th>g135</th>\n",
       "      <th>g135_1</th>\n",
       "      <th>g135_2</th>\n",
       "      <th>g135_3</th>\n",
       "      <th>g136</th>\n",
       "      <th>g136_1</th>\n",
       "      <th>g137</th>\n",
       "      <th>g137_1</th>\n",
       "      <th>g137_2</th>\n",
       "      <th>g138</th>\n",
       "      <th>g138_1</th>\n",
       "      <th>g139</th>\n",
       "      <th>g139_1</th>\n",
       "      <th>g140</th>\n",
       "      <th>g140_1</th>\n",
       "      <th>g140_2</th>\n",
       "      <th>g140_3</th>\n",
       "      <th>g141</th>\n",
       "      <th>g141_1</th>\n",
       "      <th>g141_2</th>\n",
       "      <th>g_itnd_1</th>\n",
       "      <th>g142</th>\n",
       "      <th>g_itnd_2</th>\n",
       "      <th>g143</th>\n",
       "      <th>g144</th>\n",
       "      <th>g144_1</th>\n",
       "      <th>g144_2_1</th>\n",
       "      <th>g144_2_2</th>\n",
       "      <th>g144_2_3</th>\n",
       "      <th>g144_2_4</th>\n",
       "      <th>g144_2_5</th>\n",
       "      <th>g_itnd_3</th>\n",
       "      <th>g259</th>\n",
       "      <th>g_it_1</th>\n",
       "      <th>g148_1_1</th>\n",
       "      <th>g148_1_2</th>\n",
       "      <th>g148_1_3</th>\n",
       "      <th>g148_1_5</th>\n",
       "      <th>g148_1_6</th>\n",
       "      <th>g148_1_7</th>\n",
       "      <th>g148_1_8</th>\n",
       "      <th>g148_1_9</th>\n",
       "      <th>g148_1_10</th>\n",
       "      <th>g148_1_11</th>\n",
       "      <th>g148_1_12</th>\n",
       "      <th>g_it_2</th>\n",
       "      <th>g148_2_1</th>\n",
       "      <th>g148_2_2</th>\n",
       "      <th>g148_2_3</th>\n",
       "      <th>g148_2_5</th>\n",
       "      <th>g148_2_6</th>\n",
       "      <th>g148_2_7</th>\n",
       "      <th>g148_2_8</th>\n",
       "      <th>g148_2_9</th>\n",
       "      <th>g148_2_10</th>\n",
       "      <th>g148_2_11</th>\n",
       "      <th>g148_2_12</th>\n",
       "      <th>g148_3</th>\n",
       "      <th>g148_4</th>\n",
       "      <th>g148_5_1</th>\n",
       "      <th>g148_5_2</th>\n",
       "      <th>g149</th>\n",
       "      <th>g149_1</th>\n",
       "      <th>g150</th>\n",
       "      <th>g255</th>\n",
       "      <th>g256</th>\n",
       "      <th>g152</th>\n",
       "      <th>g151_6</th>\n",
       "      <th>g151_3</th>\n",
       "      <th>g151_4</th>\n",
       "      <th>g257</th>\n",
       "      <th>g153</th>\n",
       "      <th>g153_1</th>\n",
       "      <th>g153_2</th>\n",
       "      <th>g258</th>\n",
       "      <th>g258_1</th>\n",
       "      <th>g154</th>\n",
       "      <th>g154_1</th>\n",
       "      <th>h155</th>\n",
       "      <th>h155_1</th>\n",
       "      <th>h156</th>\n",
       "      <th>h156_1</th>\n",
       "      <th>h272</th>\n",
       "      <th>h272_1</th>\n",
       "      <th>h273</th>\n",
       "      <th>h273_1</th>\n",
       "      <th>h274</th>\n",
       "      <th>h274_1</th>\n",
       "      <th>h274_2</th>\n",
       "      <th>h274_3</th>\n",
       "      <th>h252</th>\n",
       "      <th>h252_1</th>\n",
       "      <th>h158_1</th>\n",
       "      <th>h158_2</th>\n",
       "      <th>h159</th>\n",
       "      <th>h160</th>\n",
       "      <th>h160_1</th>\n",
       "      <th>h160_2</th>\n",
       "      <th>h161</th>\n",
       "      <th>h162</th>\n",
       "      <th>h163_1</th>\n",
       "      <th>h163_2</th>\n",
       "      <th>h164</th>\n",
       "      <th>h165</th>\n",
       "      <th>h227</th>\n",
       "      <th>h166</th>\n",
       "      <th>h269</th>\n",
       "      <th>h269_1</th>\n",
       "      <th>h167_1</th>\n",
       "      <th>h167_1_3</th>\n",
       "      <th>h167_2</th>\n",
       "      <th>h167_2_3</th>\n",
       "      <th>h167_3</th>\n",
       "      <th>h167_3_3</th>\n",
       "      <th>h167_4</th>\n",
       "      <th>h167_4_3</th>\n",
       "      <th>h169</th>\n",
       "      <th>h170_3</th>\n",
       "      <th>h271</th>\n",
       "      <th>h271_1</th>\n",
       "      <th>h171</th>\n",
       "      <th>h171_1</th>\n",
       "      <th>h171_2</th>\n",
       "      <th>h172</th>\n",
       "      <th>h172_1</th>\n",
       "      <th>h173</th>\n",
       "      <th>h173_1</th>\n",
       "      <th>i228</th>\n",
       "      <th>i174</th>\n",
       "      <th>i259</th>\n",
       "      <th>i175</th>\n",
       "      <th>eg_ahorro</th>\n",
       "      <th>eg_ps3</th>\n",
       "      <th>eg_ps4</th>\n",
       "      <th>eg_ps5</th>\n",
       "      <th>eg_ps6</th>\n",
       "      <th>eg_ps7</th>\n",
       "      <th>eg_ps8</th>\n",
       "      <th>eg_ps1</th>\n",
       "      <th>eg_ps2</th>\n",
       "      <th>POBPCOAC</th>\n",
       "      <th>SUBEMPLEO</th>\n",
       "      <th>MTO_CUOTA</th>\n",
       "      <th>MTO_EMER</th>\n",
       "      <th>MTO_HOGCON</th>\n",
       "      <th>MTO_DESAY</th>\n",
       "      <th>MTO_ALMUE</th>\n",
       "      <th>MTO_VACAS</th>\n",
       "      <th>MTO_OVEJA</th>\n",
       "      <th>MTO_CABALL</th>\n",
       "      <th>INDACELIAC</th>\n",
       "      <th>INDAEMER</th>\n",
       "      <th>PT1</th>\n",
       "      <th>PT2</th>\n",
       "      <th>PT4</th>\n",
       "      <th>HT11</th>\n",
       "      <th>HT19</th>\n",
       "      <th>HT13</th>\n",
       "      <th>YSVL</th>\n",
       "      <th>YHOG</th>\n",
       "      <th>AFAM_H_DEC</th>\n",
       "      <th>AFAM_H</th>\n",
       "      <th>TUS_H_DEC</th>\n",
       "      <th>TUS_H</th>\n",
       "      <th>USO_RRAA</th>\n",
       "      <th>pobre06</th>\n",
       "      <th>indig06</th>\n",
       "      <th>lp_06</th>\n",
       "      <th>li_06</th>\n",
       "      <th>pobre_multi</th>\n",
       "      <th>YDA_SVL</th>\n",
       "      <th>lp_17</th>\n",
       "      <th>li_17</th>\n",
       "      <th>pobre17</th>\n",
       "      <th>indig17</th>\n",
       "      <th>monto_imput_UTE</th>\n",
       "      <th>monto_imput_GAS</th>\n",
       "      <th>monto_imput_OSE</th>\n",
       "      <th>H_FONASA</th>\n",
       "      <th>montoGAS_RRAA</th>\n",
       "      <th>montoUTE_RRAA</th>\n",
       "      <th>montoOSE_RRAA</th>\n",
       "      <th>YDA</th>\n",
       "      <th>W_TRI</th>\n",
       "      <th>W_SEM</th>\n",
       "      <th>W_ANO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57612</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1010</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>1294.12</td>\n",
       "      <td>1358.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>114.33</td>\n",
       "      <td>22.87</td>\n",
       "      <td>171.5</td>\n",
       "      <td>1238.74</td>\n",
       "      <td>1044.32</td>\n",
       "      <td>68000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72206.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72206.36</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19706.107951</td>\n",
       "      <td>5351.088451</td>\n",
       "      <td>0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>22576.809157</td>\n",
       "      <td>5977.185549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>153</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57613</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1010</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>40000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>1294.12</td>\n",
       "      <td>1358.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>114.33</td>\n",
       "      <td>22.87</td>\n",
       "      <td>171.5</td>\n",
       "      <td>1238.74</td>\n",
       "      <td>1044.32</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54206.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54206.36</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19706.107951</td>\n",
       "      <td>5351.088451</td>\n",
       "      <td>0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>22576.809157</td>\n",
       "      <td>5977.185549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>124</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57614</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1010</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>1294.12</td>\n",
       "      <td>1358.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>114.33</td>\n",
       "      <td>22.87</td>\n",
       "      <td>171.5</td>\n",
       "      <td>1238.74</td>\n",
       "      <td>1044.32</td>\n",
       "      <td>49000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>78206.36</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>53206.36</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19706.107951</td>\n",
       "      <td>5351.088451</td>\n",
       "      <td>0</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>13801.984683</td>\n",
       "      <td>5977.185549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>153</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57615</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1010</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36000</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>55172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2261</td>\n",
       "      <td>8610</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>1294.12</td>\n",
       "      <td>1358.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>114.33</td>\n",
       "      <td>22.87</td>\n",
       "      <td>171.5</td>\n",
       "      <td>1238.74</td>\n",
       "      <td>1044.32</td>\n",
       "      <td>83412.72</td>\n",
       "      <td>83412.72</td>\n",
       "      <td>83412.72</td>\n",
       "      <td>228412.72</td>\n",
       "      <td>2</td>\n",
       "      <td>25000</td>\n",
       "      <td>203412.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35695.717525</td>\n",
       "      <td>10702.176902</td>\n",
       "      <td>0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>26555.962587</td>\n",
       "      <td>11954.371097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8412.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>144</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57615</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1010</td>\n",
       "      <td>Montevideo</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36000</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>55138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66238</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1212</td>\n",
       "      <td>1061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4206.36</td>\n",
       "      <td>1294.12</td>\n",
       "      <td>1358.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>114.33</td>\n",
       "      <td>22.87</td>\n",
       "      <td>171.5</td>\n",
       "      <td>1238.74</td>\n",
       "      <td>1044.32</td>\n",
       "      <td>120000.00</td>\n",
       "      <td>120000.00</td>\n",
       "      <td>120000.00</td>\n",
       "      <td>228412.72</td>\n",
       "      <td>2</td>\n",
       "      <td>25000</td>\n",
       "      <td>203412.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35695.717525</td>\n",
       "      <td>10702.176902</td>\n",
       "      <td>0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>26555.962587</td>\n",
       "      <td>11954.371097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8412.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>144</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  nper  anio  mes  GR  region  REGION_4  dpto    nom_dpto  ccz  barrio  secc  ESTRED13  LOC_AGR_13 NOM_LOC_AGR_13  c1  c2  c3  c4  c5_2  c5_10  c5_11  c5_12  c5_13  c6  c6_1  d8_1   d8_2   d8_3  d8_4  d9  d10  d11  d12  d13  d14  d15  d16  d18  d260  d19  d20  d21_1  d21_2  d21_3  d21_6  d21_4  d21_4_1  d21_5  d21_5_1  d21_20  d21_7  d21_10  d21_11  d21_12  d21_13  d21_14  d21_14_1  d21_15  d21_15_1  d21_15_2  d21_15_3  d21_15_4  d21_15_5  d21_15_6  d21_16  d21_16_1  d21_16_2  d21_21  d21_17  d21_18  d21_18_1  d21_19  d21_19_1  d181  d229  d230  d231  d232  d184  d184_1  d181_b  d184_b  d23  d24  d25  e557  e26  e27  e29_1  e29_2  e29_3  e29_4  e29_5  e29_6  e30  e31  e31_1  e32  e32_1  e33  e34  e35  e36  e185  e186_1  e186_2  e186_3  e186_4  e37  e37_2  e234_2  e38  e38_1  e39  e39_2  e235_2  e236  e236_2  e236_4  e45_cv  e45_1_1_cv  e45_1_1_1_cv  e45_2_1_cv  e45_2_1_1_cv  e45_3_1_cv  e45_3_1_1_cv  e45_4_1_cv  e45_4_1_1_cv  e45_cva  e45_cvb  e46_cv  e47_cv  e47_1_cv  e190  e48  e49  e49a  e579  e583  e581  e579a  e581a  e582  e582_1  e582_2  e582_3  e51_2  e197_1  e51_3  e51_4_a  e201_1a  e51_4_b  e201_1b  e51_5  e201_1c  e51_6  e201_1d  e209_1  e202  e51_6a  e51_6b  e214_1  e51_8  e215_1  e217_1  e51_9  e218_1  e220_1  e51_10  e221_1  e223_1  e51_11  e224_1  e226_1  e559  e559_1  e559_2  e584  e584_1  e59  e246  e247  f269  f270  f271  f272  f273  f69  f69_1  f274  f275  f276  f277  f70  f71_2  f72_2  f73  f82  f83  f84  f278  f278_a  f279  f280_1  f280_2  f280_3  f281_1  f281_2  f281_3  f281_4  f75  f76_2  f283  f81  f266  f266_1  f266_2  f267  f268  f77  f305  f306  f78  f80  f80_2  f284_1  f284_2  f284_3  f284_4  f284_5  f284_6  f284_7  f285  f286  f287  f85  f307  f308  f288  f289  f290  f291_a  f291_b  f292  f293  f294  f295  f90_2  f91_2  f92  f96  f97  f93  f94  f94_2  f296_1  f296_2  f296_3  f296_4  f296_5  f296_6  f296_7  f98  f99  f100  f101  f102  f103  f297  f298  f104  f299  f110  f111  f113  f114  f115  f300  f108  f301  f106  f116  f117  f118_1  f118_2  f122  f119_2  f120_2  f121  f123  f124_1  f124_2  f124_3  f124_5  f125  g_id_1  g_id_2  g_id_3  g_id_1a  g_id_2a  g_id_3a  g126_1  g126_2  g126_3  g126_4  g126_5  g126_6  g126_7  g126_8  g250_1  g250_2  g250_3  g250_4  g250_5  g127  g127_1  g127_2  g127_3  g128  g128_1  g129  g129_1  g129_2  g130  g130_1  g131  g131_1  g132  g132_1  g132_2  g132_3  g133  g133_1  g133_2  g_st_1  g134_1  g134_2  g134_3  g134_4  g134_5  g134_6  g134_7  g134_8  g251_1  g251_2  g251_3  g251_4  g251_5  g135  g135_1  g135_2  g135_3  g136  g136_1  g137  g137_1  g137_2  g138  g138_1  g139  g139_1  g140  g140_1  g140_2  g140_3  g141  g141_1  g141_2  g_itnd_1  g142  g_itnd_2  g143  g144  g144_1  g144_2_1  g144_2_2  g144_2_3  g144_2_4  g144_2_5  g_itnd_3  g259  g_it_1  g148_1_1  g148_1_2  g148_1_3  g148_1_5  g148_1_6  g148_1_7  g148_1_8  g148_1_9  g148_1_10  g148_1_11  g148_1_12  g_it_2  g148_2_1  g148_2_2  g148_2_3  g148_2_5  g148_2_6  g148_2_7  g148_2_8  g148_2_9  g148_2_10  g148_2_11  g148_2_12  g148_3  g148_4  g148_5_1  g148_5_2  g149  g149_1  g150  g255  g256  g152  g151_6  g151_3  g151_4  g257  g153  g153_1  g153_2  g258  g258_1  g154  g154_1  h155  h155_1  h156  h156_1  h272  h272_1  h273  h273_1  h274  h274_1  h274_2  h274_3  h252  h252_1  h158_1  h158_2  h159  h160  h160_1  h160_2  h161  h162  h163_1  h163_2  h164  h165  h227  h166  h269  h269_1  h167_1  h167_1_3  h167_2  h167_2_3  h167_3  h167_3_3  h167_4  h167_4_3  h169  h170_3  h271  h271_1  h171  h171_1  h171_2  h172  h172_1  h173  h173_1  i228  i174  i259  i175  eg_ahorro  eg_ps3  eg_ps4  eg_ps5  eg_ps6  eg_ps7  eg_ps8  eg_ps1  eg_ps2  POBPCOAC  SUBEMPLEO  MTO_CUOTA  MTO_EMER  MTO_HOGCON  MTO_DESAY  MTO_ALMUE  MTO_VACAS  MTO_OVEJA  MTO_CABALL  INDACELIAC  INDAEMER        PT1        PT2        PT4       HT11  HT19   HT13       YSVL     YHOG  AFAM_H_DEC  AFAM_H  TUS_H_DEC  TUS_H  USO_RRAA  pobre06  indig06         lp_06         li_06  pobre_multi   YDA_SVL         lp_17         li_17  pobre17  indig17  monto_imput_UTE  monto_imput_GAS  monto_imput_OSE  H_FONASA  montoGAS_RRAA  montoUTE_RRAA  montoOSE_RRAA       YDA  W_TRI  W_SEM  W_ANO\n",
       "0  57612     1  2024    1  31       1         1     1  Montevideo    1       2     1         4        1010     Montevideo   3   1   1   1     2      2      2      2    NaN   1     0     5      0  18000     2   2    1    1    1    1    1    1    1    1     6    1    3      1      2      1      2      2        0      1        1       2      1       1       2       2       1       2         0       1         2         0         1         1         2         0       1         1         2       2       1       2         0       2         0   2.0   0.0   0.0   0.0   0.0   2.0     0.0     NaN     NaN    1    0    1     1    2   70      2      2      1      2      2      0    1    0      0    0      0    2    0    0    4     1       0       2       0       1    1      0       0    1      0    0      0       0     0       0       0       4           0             0           0             0           0             0           1             1        7        0       1       2         0     3    1    1    20     0     0     0      0      0     0       0       0       0      6       1      0        3        1        0        0      3        1      0        0       0     0       0       0       0      0       0       0      0       0       0       0       0       0       0       0       0     2       0       0     2       0    2     0     0     2     2     0     0     2    0      0     0     0     2     0    0      0      0    0    0    0    0     0       0     0       0       0       0       0       0       0       0    0      0     0    0     0       0       0     0     0    0     0     0    0    0      0       0       0       0       0       0       0       0     0     0     0    0     0     0   0.0   0.0   0.0     0.0     0.0   0.0   0.0   0.0   0.0      0      0    0    0    0    0    0      0       0       0       0       0       0       0       0    0    0     0     0     0     0     0     0     0     2     0     0     0     0     0     2    10     0     3     1     2       0      30     8       0       0     0     0       1       1       2       1     2       2       2       2        0        0        0       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0         2     0         2     0     2       0         0         0         0         0         0         3     0       1         0         0         0         0     28000         0         0         0          0          0          0       1     40000         0         0         0         0         0         0         0          0          0          0       0       0         0         0     2       0     3     0     0     0       0       0       0     0     2       0       0     2       0     2       0     2       0     2       0     2       0     2       0     2       0       0       0     2       0       0       0     2     0       0       0     2     0       0       0     0     0     2     0     2       0       3         0       2         0       2         0       2         0     2       0     2       0     2       0       0     2       0     2       0     2     0     2     0          2       2       2       2       2       2       4       1  100000        10          0    4206.36   1294.12      1358.4       47.4      162.6     114.33      22.87       171.5     1238.74   1044.32   68000.00       0.00       0.00   72206.36     1      0   72206.36  4206.36           0     0.0          0      0         0        0        0  19706.107951   5351.088451            0   68000.0  22576.809157   5977.185549        0        0              0.0              0.0              0.0   4206.36            0.0            0.0            0.0   68000.0    153     72     32\n",
       "1  57613     1  2024    1  31       1         1     1  Montevideo    1       2     1         4        1010     Montevideo   3   1   1   1     2      2      2      2    NaN   1     0     5      0  20000     2   2    1    1    1    1    1    1    1    1     6    1    3      1      2      1      1      2        0      1        1       2      1       2       2       2       2       2         0       2         0         0         0         0         0         0       2         0         0       2       2       2         0       2         0   2.0   0.0   0.0   0.0   0.0   2.0     0.0     NaN     NaN    1    0    1     1    1   91      2      2      1      2      2      0    1    0      0    0      0    2    0    0    2     0       0       0       0       0    1      0       0    1      0    0      0       0     0       0       0       2           0             0           1             0           0             0           0             0        7        0       2       0         0     3    1    1    14     0     0     0      0      0     0       0       0       0      6       1      0        1        2        0        0      0        0      0        0       0     0       0       0       0      0       0       0      0       0       0       0       0       0       0       0       0     2       0       0     2       0    2     0     0     2     2     0     0     2    0      0     0     0     2     0    0      0      0    0    0    0    0     0       0     0       0       0       0       0       0       0       0    0      0     0    0     0       0       0     0     0    0     0     0    0    0      0       0       0       0       0       0       0       0     0     0     0    0     0     0   0.0   0.0   0.0     0.0     0.0   0.0   0.0   0.0   0.0      0      0    0    0    0    0    0      0       0       0       0       0       0       0       0    0    0     0     0     0     0     0     0     0     2     0     0     0     0     0     2    10     0     3     1     2       0      22     8       0       0     0     0       1       2       2       1     0       2       2       2        0        0        0       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0         2     0         2     0     2       0         0         0         0         0         0         3     0       1         0     50000         0         0         0         0         0         0          0          0          0       2         0         0         0         0         0         0         0         0          0          0          0       0       0         0         0     2       0     3     0     0     0       0       0       0     0     2       0       0     2       0     2       0     2       0     2       0     2       0     2       0     2       0       0       0     2       0       0       0     2     0       0       0     2     0       0       0     0     0     2     0     2       0       3         0       2         0       2         0       2         0     2       0     2       0     2       0       0     2       0     2       0     2     0     2     0          2       2       2       2       2       2       4       2   40000        10          0    4206.36   1294.12      1358.4       47.4      162.6     114.33      22.87       171.5     1238.74   1044.32   50000.00       0.00       0.00   54206.36     1      0   54206.36  4206.36           0     0.0          0      0         0        0        0  19706.107951   5351.088451            0   50000.0  22576.809157   5977.185549        0        0              0.0              0.0              0.0   4206.36            0.0            0.0            0.0   50000.0    124     59     30\n",
       "2  57614     1  2024    1  31       1         1     1  Montevideo    1       2     1         4        1010     Montevideo   3   1   1   1     2      2      2      2    NaN   1     0     2      0  25000     2   2    1    1    1    1    1    1    1    1     3    1    3      1      2      1      1      2        0      1        2       2      1       2       2       2       1       1         1       2         0         0         0         0         0         0       1         1         2       2       1       2         0       2         0   2.0   0.0   0.0   0.0   0.0   2.0     0.0     NaN     NaN    1    0    1     1    2   79      2      2      1      2      2      0    1    0      0    0      0    2    0    0    6     2       0       0       0       0    3     12       0    2     45    2     11       0     0       0       0       2           0             0           1             0           0             0           0             0        7        0       1       2         0     4    1    1    17     0     0     0      0      0     0       0       0       0      6       1      0        3        1        0        0      1        2      0        0       0     0       0       0       0      0       0       0      0       0       0       0       0       0       0       0       0     2       0       0     2       0    2     0     0     2     2     0     0     2    0      0     0     0     2     0    0      0      0    0    0    0    0     0       0     0       0       0       0       0       0       0       0    0      0     0    0     0       0       0     0     0    0     0     0    0    0      0       0       0       0       0       0       0       0     0     0     0    0     0     0   0.0   0.0   0.0     0.0     0.0   0.0   0.0   0.0   0.0      0      0    0    0    0    0    0      0       0       0       0       0       0       0       0    0    0     0     0     0     0     0     0     0     2     0     0     0     0     0     2    10     0     3     1     2       0      15     8       0       0     0     0       1       2       2       1     0       2       2       2        0        0        0       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0         2     0         2     0     2       0         0         0         0         0         0         3     0       1     49000         0         0         0         0         0         0         0          0          0          0       2         0         0         0         0         0         0         0         0          0          0          0       0       0         0         0     2       0     3     0     0     0       0       0       0     0     2       0       0     2       0     2       0     2       0     2       0     2       0     2       0     2       0       0       0     2       0       1       0     2     0       0       0     2     0       0       0     0     0     2     0     2       0       3         0       2         0       2         0       2         0     2       0     2       0     2       0       0     2       0     2       0     2     0     2     0          2       2       2       2       2       2       4       2   50000        10          0    4206.36   1294.12      1358.4       47.4      162.6     114.33      22.87       171.5     1238.74   1044.32   49000.00       0.00       0.00   78206.36     1  25000   53206.36  4206.36           0     0.0          0      0         0        0        0  19706.107951   5351.088451            0   49000.0  13801.984683   5977.185549        0        0              0.0              0.0              0.0   4206.36            0.0            0.0            0.0   74000.0    153     72     32\n",
       "3  57615     1  2024    1  31       1         1     1  Montevideo    1       2     1         4        1010     Montevideo   3   1   1   1     2      2      2      2    NaN   1     0     1  36000  25000     2   3    1    1    1    1    1    1    1    1     1    1    3      1      2      1      1      2        0      1        2       2      2       1       1       2       1       1         1       1         2         0         1         2         2         0       1         1         2       1       2       1         1       2         0   2.0   0.0   0.0   0.0   0.0   2.0     0.0     NaN     NaN    2    0    2     1    2   40      2      2      1      2      2      0    1    0      0    0      0    1    2    4    0     2       0       0       0       0    4      0     152    2     38    3      0     152     0       0       0       4           0             0           0             0           0             0           1             1        2        2       2       0         0     4    1    3     0    10     0     1      7      0     0       0       0       0      6       1      0        3        1        0        0      3        1      0        0       0     0       0       0       0      0       0       0      6       2   55172       0       0       0       0       0       0     2       0       0     2       0    2     0     0     1     0     1     0     0    0      0     0     0     0     0    1   2261   8610    2    1    4    1     1       0     1       2       2       2       0       0       0       0    1      0     6    1     1       1       0     2     2    9     0     0   13    1      0       4       4       4       4       4       0       0     2     0     0   20  2007     0   3.0   0.0   0.0     0.0     2.0   0.0   0.0   0.0   0.0      0      0    0    0    0    0    0      0       0       0       0       0       0       0       0    0    2     0     0     2     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0       0       0     0       0       0     0     0       2       2       2       1     0       0       0       0        0        0        0   50000       0       0       0   25000       0       0       0       2       1       2       2       2     2       0       0       0     2       0     2       0       0     2       0     2       0     3       0       0       0     0       0       0       2       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0         2     0         2     0     2       0         0         0         0         0         0         3     0       2         0         0         0         0         0         0         0         0          0          0          0       2         0         0         0         0         0         0         0         0          0          0          0       0       0         0         0     1       1     3     0     0     0       0       0       0     0     2       0       0     2       0     2       0     2       0     2       0     2       0     2       0     2       0       0       0     2       0       1       2     2     0       0       0     2     0       0       0     0     0     2     0     2       0       3         0       2         0       2         0       2         0     2       0     2       0     2       0       0     2       0     2       0     2     0     2     0          1       2       2       2       2       2       4       2  180000         2          0    4206.36   1294.12      1358.4       47.4      162.6     114.33      22.87       171.5     1238.74   1044.32   83412.72   83412.72   83412.72  228412.72     2  25000  203412.72     0.00           0     0.0          0      0         0        0        0  35695.717525  10702.176902            0  195000.0  26555.962587  11954.371097        0        0              0.0              0.0              0.0   8412.72            0.0            0.0            0.0  220000.0    144     76     34\n",
       "4  57615     2  2024    1  31       1         1     1  Montevideo    1       2     1         4        1010     Montevideo   3   1   1   1     2      2      2      2    NaN   1     0     1  36000  25000     2   3    1    1    1    1    1    1    1    1     1    1    3      1      2      1      1      2        0      1        2       2      2       1       1       2       1       1         1       1         2         0         1         2         2         0       1         1         2       1       2       1         1       2         0   2.0   0.0   0.0   0.0   0.0   2.0     0.0     NaN     NaN    2    0    2     2    2   36      2      2      1      2      2      0    2    0      0    0      0    1    1    4    0     2       0       0       0       0    3     16       0    2     10    2     16       0     0       0       0       4           0             0           0             0           0             0           1             1        2        2       2       0         0     4    1    1    27     0     0     0      0      0     0       0       0       0      6       1      0        3        1        0        0      3        1      0        0       0     0       0       0       0      0       0       0      6       1   55138       0       0       0       2       1   66238     2       0       0     2       0    2     0     0     1     0     1     0     0    0      0     0     0     0     0    1   1212   1061    1    1    2    1     1       0     1       2       2       2       0       0       0       0    1      0     6    1     2       0       2     1     1    9     4     0   13    2      0       8       8       8       8       8       0       0     2     0     0   40  2014     0   3.0   0.0   0.0     0.0     2.0   0.0   0.0   0.0   0.0      0      0    0    0    0    0    0      0       0       0       0       0       0       0       0    0    2     0     0     2     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0       0       0     0       0       0     0     0       2       2       2       1     0       0       0       0        0        0        0   80000       0       0       0   40000       0       0       0       2       1       2       2       2     2       0       0       0     2       0     2       0       0     2       0     2       0     3       0       0       0     0       0       0       2       0       0       0       0       0       0       0       0       0       0       0       0       0     0       0       0       0     0       0     0       0       0     0       0     0       0     0       0       0       0     0       0       0         2     0         2     0     2       0         0         0         0         0         0         3     0       2         0         0         0         0         0         0         0         0          0          0          0       2         0         0         0         0         0         0         0         0          0          0          0       0       0         0         0     2       0     3     0     0     0       0       0       0     0     2       0       0     2       0     2       0     2       0     2       0     2       0     2       0     2       0       0       0     2       0       1       2     2     0       0       0     2     0       0       0     0     0     2     0     2       0       3         0       2         0       2         0       2         0     2       0     2       0     2       0       0     2       0     2       0     2     0     2     0          1       2       2       2       2       2       4       2  180000         2          0    4206.36   1294.12      1358.4       47.4      162.6     114.33      22.87       171.5     1238.74   1044.32  120000.00  120000.00  120000.00  228412.72     2  25000  203412.72     0.00           0     0.0          0      0         0        0        0  35695.717525  10702.176902            0  195000.0  26555.962587  11954.371097        0        0              0.0              0.0              0.0   8412.72            0.0            0.0            0.0  220000.0    144     76     34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DIMENSIONES Y PRIMERAS FILAS\n",
    "print(\"Dimensiones del dataset:\", ech.shape)\n",
    "print(\"\\nPrimeras filas:\")\n",
    "display(ech.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ef4996b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int64      484\n",
       "float64     49\n",
       "object       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TIPOS DE DATOS\n",
    "print(\"\\nTipos de datos:\")\n",
    "display(ech.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1b1f2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'nper', 'anio', 'mes', 'GR', 'region', 'REGION_4', 'dpto', 'nom_dpto', 'ccz', 'barrio', 'secc', 'ESTRED13', 'LOC_AGR_13', 'NOM_LOC_AGR_13', 'c1', 'c2', 'c3', 'c4', 'c5_2', 'c5_10', 'c5_11', 'c5_12', 'c5_13', 'c6', 'c6_1', 'd8_1', 'd8_2', 'd8_3', 'd8_4', 'd9', 'd10', 'd11', 'd12', 'd13', 'd14', 'd15', 'd16', 'd18', 'd260', 'd19', 'd20', 'd21_1', 'd21_2', 'd21_3', 'd21_6', 'd21_4', 'd21_4_1', 'd21_5', 'd21_5_1', 'd21_20', 'd21_7', 'd21_10', 'd21_11', 'd21_12', 'd21_13', 'd21_14', 'd21_14_1', 'd21_15', 'd21_15_1', 'd21_15_2', 'd21_15_3', 'd21_15_4', 'd21_15_5', 'd21_15_6', 'd21_16', 'd21_16_1', 'd21_16_2', 'd21_21', 'd21_17', 'd21_18', 'd21_18_1', 'd21_19', 'd21_19_1', 'd181', 'd229', 'd230', 'd231', 'd232', 'd184', 'd184_1', 'd181_b', 'd184_b', 'd23', 'd24', 'd25', 'e557', 'e26', 'e27', 'e29_1', 'e29_2', 'e29_3', 'e29_4', 'e29_5', 'e29_6', 'e30', 'e31', 'e31_1', 'e32', 'e32_1', 'e33', 'e34', 'e35', 'e36', 'e185', 'e186_1', 'e186_2', 'e186_3', 'e186_4', 'e37', 'e37_2', 'e234_2', 'e38', 'e38_1', 'e39', 'e39_2', 'e235_2', 'e236', 'e236_2', 'e236_4', 'e45_cv', 'e45_1_1_cv', 'e45_1_1_1_cv', 'e45_2_1_cv', 'e45_2_1_1_cv', 'e45_3_1_cv', 'e45_3_1_1_cv', 'e45_4_1_cv', 'e45_4_1_1_cv', 'e45_cva', 'e45_cvb', 'e46_cv', 'e47_cv', 'e47_1_cv', 'e190', 'e48', 'e49', 'e49a', 'e579', 'e583', 'e581', 'e579a', 'e581a', 'e582', 'e582_1', 'e582_2', 'e582_3', 'e51_2', 'e197_1', 'e51_3', 'e51_4_a', 'e201_1a', 'e51_4_b', 'e201_1b', 'e51_5', 'e201_1c', 'e51_6', 'e201_1d', 'e209_1', 'e202', 'e51_6a', 'e51_6b', 'e214_1', 'e51_8', 'e215_1', 'e217_1', 'e51_9', 'e218_1', 'e220_1', 'e51_10', 'e221_1', 'e223_1', 'e51_11', 'e224_1', 'e226_1', 'e559', 'e559_1', 'e559_2', 'e584', 'e584_1', 'e59', 'e246', 'e247', 'f269', 'f270', 'f271', 'f272', 'f273', 'f69', 'f69_1', 'f274', 'f275', 'f276', 'f277', 'f70', 'f71_2', 'f72_2', 'f73', 'f82', 'f83', 'f84', 'f278', 'f278_a', 'f279', 'f280_1', 'f280_2', 'f280_3', 'f281_1', 'f281_2', 'f281_3', 'f281_4', 'f75', 'f76_2', 'f283', 'f81', 'f266', 'f266_1', 'f266_2', 'f267', 'f268', 'f77', 'f305', 'f306', 'f78', 'f80', 'f80_2', 'f284_1', 'f284_2', 'f284_3', 'f284_4', 'f284_5', 'f284_6', 'f284_7', 'f285', 'f286', 'f287', 'f85', 'f307', 'f308', 'f288', 'f289', 'f290', 'f291_a', 'f291_b', 'f292', 'f293', 'f294', 'f295', 'f90_2', 'f91_2', 'f92', 'f96', 'f97', 'f93', 'f94', 'f94_2', 'f296_1', 'f296_2', 'f296_3', 'f296_4', 'f296_5', 'f296_6', 'f296_7', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f297', 'f298', 'f104', 'f299', 'f110', 'f111', 'f113', 'f114', 'f115', 'f300', 'f108', 'f301', 'f106', 'f116', 'f117', 'f118_1', 'f118_2', 'f122', 'f119_2', 'f120_2', 'f121', 'f123', 'f124_1', 'f124_2', 'f124_3', 'f124_5', 'f125', 'g_id_1', 'g_id_2', 'g_id_3', 'g_id_1a', 'g_id_2a', 'g_id_3a', 'g126_1', 'g126_2', 'g126_3', 'g126_4', 'g126_5', 'g126_6', 'g126_7', 'g126_8', 'g250_1', 'g250_2', 'g250_3', 'g250_4', 'g250_5', 'g127', 'g127_1', 'g127_2', 'g127_3', 'g128', 'g128_1', 'g129', 'g129_1', 'g129_2', 'g130', 'g130_1', 'g131', 'g131_1', 'g132', 'g132_1', 'g132_2', 'g132_3', 'g133', 'g133_1', 'g133_2', 'g_st_1', 'g134_1', 'g134_2', 'g134_3', 'g134_4', 'g134_5', 'g134_6', 'g134_7', 'g134_8', 'g251_1', 'g251_2', 'g251_3', 'g251_4', 'g251_5', 'g135', 'g135_1', 'g135_2', 'g135_3', 'g136', 'g136_1', 'g137', 'g137_1', 'g137_2', 'g138', 'g138_1', 'g139', 'g139_1', 'g140', 'g140_1', 'g140_2', 'g140_3', 'g141', 'g141_1', 'g141_2', 'g_itnd_1', 'g142', 'g_itnd_2', 'g143', 'g144', 'g144_1', 'g144_2_1', 'g144_2_2', 'g144_2_3', 'g144_2_4', 'g144_2_5', 'g_itnd_3', 'g259', 'g_it_1', 'g148_1_1', 'g148_1_2', 'g148_1_3', 'g148_1_5', 'g148_1_6', 'g148_1_7', 'g148_1_8', 'g148_1_9', 'g148_1_10', 'g148_1_11', 'g148_1_12', 'g_it_2', 'g148_2_1', 'g148_2_2', 'g148_2_3', 'g148_2_5', 'g148_2_6', 'g148_2_7', 'g148_2_8', 'g148_2_9', 'g148_2_10', 'g148_2_11', 'g148_2_12', 'g148_3', 'g148_4', 'g148_5_1', 'g148_5_2', 'g149', 'g149_1', 'g150', 'g255', 'g256', 'g152', 'g151_6', 'g151_3', 'g151_4', 'g257', 'g153', 'g153_1', 'g153_2', 'g258', 'g258_1', 'g154', 'g154_1', 'h155', 'h155_1', 'h156', 'h156_1', 'h272', 'h272_1', 'h273', 'h273_1', 'h274', 'h274_1', 'h274_2', 'h274_3', 'h252', 'h252_1', 'h158_1', 'h158_2', 'h159', 'h160', 'h160_1', 'h160_2', 'h161', 'h162', 'h163_1', 'h163_2', 'h164', 'h165', 'h227', 'h166', 'h269', 'h269_1', 'h167_1', 'h167_1_3', 'h167_2', 'h167_2_3', 'h167_3', 'h167_3_3', 'h167_4', 'h167_4_3', 'h169', 'h170_3', 'h271', 'h271_1', 'h171', 'h171_1', 'h171_2', 'h172', 'h172_1', 'h173', 'h173_1', 'i228', 'i174', 'i259', 'i175', 'eg_ahorro', 'eg_ps3', 'eg_ps4', 'eg_ps5', 'eg_ps6', 'eg_ps7', 'eg_ps8', 'eg_ps1', 'eg_ps2', 'POBPCOAC', 'SUBEMPLEO', 'MTO_CUOTA', 'MTO_EMER', 'MTO_HOGCON', 'MTO_DESAY', 'MTO_ALMUE', 'MTO_VACAS', 'MTO_OVEJA', 'MTO_CABALL', 'INDACELIAC', 'INDAEMER', 'PT1', 'PT2', 'PT4', 'HT11', 'HT19', 'HT13', 'YSVL', 'YHOG', 'AFAM_H_DEC', 'AFAM_H', 'TUS_H_DEC', 'TUS_H', 'USO_RRAA', 'pobre06', 'indig06', 'lp_06', 'li_06', 'pobre_multi', 'YDA_SVL', 'lp_17', 'li_17', 'pobre17', 'indig17', 'monto_imput_UTE', 'monto_imput_GAS', 'monto_imput_OSE', 'H_FONASA', 'montoGAS_RRAA', 'montoUTE_RRAA', 'montoOSE_RRAA', 'YDA', 'W_TRI', 'W_SEM', 'W_ANO']\n"
     ]
    }
   ],
   "source": [
    "# MOSTRAR TODAS LAS COLUMNAS SIN TRUNCAR\n",
    "pd.set_option('display.max_columns', None)  # muestra todas las columnas\n",
    "pd.set_option('display.expand_frame_repr', False)  # evita salto de lnea\n",
    "\n",
    "# MOSTRAR TODOS LOS NOMBRES DE COLUMNAS\n",
    "print(ech.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bae81d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas duplicadas por nombre: []\n"
     ]
    }
   ],
   "source": [
    "# VEMOS SI HAY COLUMNAS DUPLICADAS POR NOMBRES\n",
    "duplicated_cols = ech.columns[ech.columns.duplicated()].tolist()\n",
    "print(\"Columnas duplicadas por nombre:\", duplicated_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1d717",
   "metadata": {},
   "source": [
    "No hay columnas duplicadas en el dataset original. \n",
    "\n",
    "Las columnas que aparecian duplicadas y no permitian ejecutar el pipeline las repetiamos erroneamente al categorizar las variables porque si aparecen duplicadas en el Excel del diccionario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54814d06",
   "metadata": {},
   "source": [
    "## Analisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0c84aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas con nulos (cantidad):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "f295      28066\n",
       "f293      28066\n",
       "d229      28066\n",
       "d230      28066\n",
       "d231      28066\n",
       "d232      28066\n",
       "d184      28066\n",
       "d184_1    28066\n",
       "f294      28066\n",
       "d181      28066\n",
       "f288      28066\n",
       "f289      28066\n",
       "f290      28066\n",
       "f291_a    28066\n",
       "f291_b    28066\n",
       "f292      28066\n",
       "c5_13     27857\n",
       "d181_b    27857\n",
       "d184_b    27857\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANALISIS DE VALORES NULOS\n",
    "nulos = ech.isnull().sum()\n",
    "nulos = nulos[nulos > 0].sort_values(ascending=False)\n",
    "print(\"\\nColumnas con nulos (cantidad):\")\n",
    "display(nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56fb87",
   "metadata": {},
   "source": [
    "Verificando el diccionario, los valores nulos son para las variables:\n",
    "- c5_13: PROBLEMAS DE LA VIVIENDA Pisos y muros agrietados\n",
    "- d181, d181_b, d184, d184_1, d184_b, d229, d230, d231, d232: SERVICIO DOMESTICO\n",
    "- f288, f289, f290, f291_a, f291_b, f292, f293, f294, f295: Lugar y modalidad de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "35bbb696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f288      0.501869\n",
       "f295      0.501869\n",
       "d231      0.501869\n",
       "d230      0.501869\n",
       "d229      0.501869\n",
       "d181      0.501869\n",
       "d184_1    0.501869\n",
       "d184      0.501869\n",
       "f289      0.501869\n",
       "f290      0.501869\n",
       "f291_a    0.501869\n",
       "f291_b    0.501869\n",
       "f292      0.501869\n",
       "f293      0.501869\n",
       "f294      0.501869\n",
       "d232      0.501869\n",
       "d181_b    0.498131\n",
       "d184_b    0.498131\n",
       "c5_13     0.498131\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nulos_pct = ech.isnull().mean().sort_values(ascending=False)\n",
    "display(nulos_pct[nulos_pct > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241e126",
   "metadata": {},
   "source": [
    "Las preguntas son de los modulos:\n",
    "-   Servicio domstico  slo hogares que contratan personal.\n",
    "-   Lugar y modalidad de trabajo  slo personas ocupadas.\n",
    "\n",
    "Confirmamos que son variables condicionales por diseo: \n",
    "-   La mitad de la poblacin no responde esas preguntas porque no aplica.\n",
    "-   El 50% restante s tiene datos vlidos y tiles.\n",
    "\n",
    "No eliminamos esas columnas por tener demasiados nulos, ya que no se trata de datos ausentes por error, sino de lgica del cuestionario.\n",
    "\n",
    "Podemos usarlas de forma segmentada, por ejemplo:\n",
    "-   Hacer modelos distintos para personas ocupadas (que tienen datos en f288f295) y no ocupadas, o\n",
    "-   Incluir una variable indicadora de aplica o no aplica para evitar que el modelo se confunda.\n",
    "\n",
    "Son una seal indirecta de pertenencia a ciertos grupos: tener datos en esas columnas podra implicar estar ocupado o tener personal a cargo  lo que s puede estar correlacionado con el ingreso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "940ff227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadsticas de ingreso (YDA):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5.592300e+04\n",
       "mean     1.063283e+05\n",
       "std      9.331071e+04\n",
       "min      0.000000e+00\n",
       "25%      5.400000e+04\n",
       "50%      8.187355e+04\n",
       "75%      1.270000e+05\n",
       "max      2.560000e+06\n",
       "Name: YDA, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISTRIBUCION DE LA VARIABLE OBJETIVO\n",
    "# Suponemos que la variable objetivo es 'YDA'\n",
    "target = 'YDA'\n",
    "print(\"\\nEstadsticas de ingreso (YDA):\")\n",
    "display(ech[target].describe())\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(ech[target], bins=50, kde=True)\n",
    "plt.title('Distribucin del Ingreso Disponible Ajustado (YDA)')\n",
    "plt.xlabel('Ingreso')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ac456",
   "metadata": {},
   "source": [
    "Se observa que:\n",
    "- Muy asimtrica (sesgo a la derecha).\n",
    "- Muchos ingresos entre $0 y $200.000.\n",
    "- Algunos valores extremos que superan el milln (outliers evidentes).\n",
    "\n",
    "Tratamos a continuacion: \n",
    "- Usmos la variable log_YDA como target en modelos lineales y rboles si queremos reducir la sensibilidad a los valores extremos.\n",
    "- Visualizamos un boxplot ya que el max es 25 veces el 75 percentil.\n",
    "- Vemos valores en 0 ya que min = 0  Ingreso nulo o inactivo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d8fd3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET DE MODELOS LINEALES Y ARBOLES SI QUEREMOS REDUCIR LA SENSIBILIDAD A LOS VALORES EXTREMOS\n",
    "ech['log_YDA'] = np.log1p(ech['YDA'])  # log(1 + YDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a5d35503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZAMOS CON BOXPLOT\n",
    "sns.boxplot(x=ech['YDA'])\n",
    "plt.title(\"Boxplot de ingreso (YDA)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4f485",
   "metadata": {},
   "source": [
    "La grfica muestra claramente lo que ya anticipamos:\n",
    "- Una alta concentracin de valores en el rango bajo (entre $0 y $200.000).\n",
    "- Una larga cola derecha de outliers extremos, que se extienden hasta los 2.5 millones.\n",
    "\n",
    "Esto confirma que:\n",
    "- El ingreso en la ECH 2024 est fuertemente sesgado.\n",
    "- La dispersin es muy alta.\n",
    "- Los outliers son numerosos pero no necesariamente errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "946b41d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 536)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VEMOS VALORES EN CERO\n",
    "ech[ech['YDA'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e897e1",
   "metadata": {},
   "source": [
    "Esto significa que solo 12 personas tienen ingreso 0 declarado, lo cual:\n",
    "- No es un problema de datos generalizado, ni requiere imputacin.\n",
    "- Pero s vale la pena entender el perfil de estas 12 personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "09ec1319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e27</th>\n",
       "      <th>e26</th>\n",
       "      <th>f269</th>\n",
       "      <th>d8_1</th>\n",
       "      <th>d9</th>\n",
       "      <th>c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24402</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39054</th>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39055</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48247</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55002</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55003</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55226</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       e27  e26  f269  d8_1  d9  c1\n",
       "1186    30    1     2     5   1   3\n",
       "3174    64    1     2     5   3   1\n",
       "3175    61    2     2     5   3   1\n",
       "5722    52    1     1     5   2   1\n",
       "12984   61    1     2     5   2   2\n",
       "24402   49    1     2     5   2   3\n",
       "39054   51    2     1     1   3   1\n",
       "39055   64    1     2     1   3   1\n",
       "48247   26    1     1     6   2   1\n",
       "55002   47    2     2     5   1   4\n",
       "55003   33    1     1     5   1   4\n",
       "55226   63    1     1     5   2   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ech[ech['YDA'] == 0][['e27', 'e26', 'f269', 'd8_1', 'd9', 'c1']])  # o las columnas que representen edad, ocupacin, tipo de hogar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab3869",
   "metadata": {},
   "source": [
    "La mayoria inquilinos o arrendatarios (d8_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5beb52a",
   "metadata": {},
   "source": [
    "La distribucin de YDA:\n",
    "- Se comporta como es esperable en datos de ingreso.\n",
    "- No requiere imputacin de nulos en YDA (no hay).\n",
    "\n",
    "Conclusiones clave:\n",
    "- Los valores extremos estn presentes, pero no dominan.\n",
    "- No es necesario eliminarlos todava. Algunos modelos (como rboles) los manejan bien.\n",
    "\n",
    "Transformacin logartmica es aconsejable.\n",
    "Especialmente para modelos sensibles a la escala o distribucin (Regresin Lineal, Redes Neuronales).\n",
    "\n",
    "Pocos casos con ingreso cero.\n",
    "Son casos especiales que pods dejar o filtrar si hacs segmentacin (ej. \"ocupados\", \"con ingreso distinto de cero\", etc.).\n",
    "\n",
    "S se beneficia de:\n",
    "- Log-transformacin (log1p).\n",
    "- Revisin de outliers extremos.\n",
    "- Segmentacin posterior por tipo de poblacin (ocupada/no ocupada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f12822a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55923, 536)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4a992f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables numricas: 533\n",
      "Variables categricas: 2\n"
     ]
    }
   ],
   "source": [
    "# IDENTIFICAMOS VARIABLES NUMERICAS Y CATEGORICAS\n",
    "num_vars = ech.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_vars = ech.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# ELIMINAMOS LA VARIABLE TARGET DE AMBAS LISTAS SI ESTA INCLUIDA\n",
    "if target in num_vars: num_vars.remove(target)\n",
    "if target in cat_vars: cat_vars.remove(target)\n",
    "\n",
    "print(f\"Variables numricas: {len(num_vars)}\")\n",
    "print(f\"Variables categricas: {len(cat_vars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "49e8bec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nom_dpto', 'NOM_LOC_AGR_13']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f5361",
   "metadata": {},
   "source": [
    "Descartamos las variables categoricas para quedarnos con un dataset numerico ya que estas variables tambien estan como numericas en las siguientes variables:\n",
    "- dpto: Cdigo correlativo del 1 al 19 comenzando por Montevideo y continuando alfabticamente.\n",
    "- LOC_AGR_13: Cdigo de las localidades agrupadas donde se releva la ECH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7dbb2d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variables eliminadas: ['nom_dpto', 'NOM_LOC_AGR_13']\n",
      "Shape resultante: (55923, 534)\n"
     ]
    }
   ],
   "source": [
    "# ELIMINAR LAS VARIABLES CATEGORICAS\n",
    "ech = ech.drop(columns=cat_vars, errors='ignore')\n",
    "\n",
    "print(\" Variables eliminadas:\", cat_vars)\n",
    "print(\"Shape resultante:\", ech.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a8ddf",
   "metadata": {},
   "source": [
    "Muchas de las variables numericas son categricas que estn codificadas numricamente, por ejemplo:\n",
    "- sexo: 1 = Hombre, 2 = Mujer\n",
    "- estado civil actual: 1 = Separado, 2 = Divorciado, 3 = Casado, etc.\n",
    "- nivel que esta cursando: 4 = Educacion media basica, 6 = Educacion media superior, etc.\n",
    "\n",
    "Estas se almacenan como int64 o float64, por lo que pandas las interpreta como numricas, cuando en realidad son categricas, ordinales o nominales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927837f",
   "metadata": {},
   "source": [
    "Imputacin condicional basada en la lgica del cuestionario:\n",
    "\n",
    "Si PERSONAS PAGAS PARA REALIZAR TAREAS DOMSTICAS O DE CUIDADOS d181 (*) 1 = S / 2 = No es 2 = No entonces:\n",
    "- PERSONAS CONTRATADAS PARA REALIZAR TAREAS  DOMSTICAS O DE CUIDADO d229 (*) N Cantidad de personas contratadas es 0.\n",
    "- CANTIDAD DE HORAS TRABAJADAS A LA SEMANA d230 (*) N Cantidad de horas habitualmente trabajadas en la semana es 0.\n",
    "- PERNOCTA EN EL HOGAR d231 (*) 1 = S / 2 = No es 2 = No.\n",
    "- CANTIDAD DE PERSONAS QUE PERNOCTAN d232 (*) N Cantidad de personas que pernoctan en el hogar es 0.\n",
    "\n",
    "Si AYUDA GRATUITA DE OTROS FAMILIARES QUE NO INTEGRAN EL HOGAR d184 (*) 1 = S / 2 = No es 2 = No entonces:\n",
    "- CANTIDAD DE HORAS TRABAJADAS A LA SEMANA d184_1 (*) N Cantidad de horas habitualmente trabajadas en la semana es 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4b185f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si d181 == 2 (no tiene servicio domstico), completar columnas relacionadas\n",
    "\n",
    "# Estas deben ser 0 si estn vacas\n",
    "for col in ['d229', 'd230', 'd232']:\n",
    "    ech.loc[(ech['d181'] == 2) & (ech[col].isnull()), col] = 0\n",
    "\n",
    "# Esta debe ser 2 si est vaca (respuesta negativa explcita)\n",
    "ech.loc[(ech['d181'] == 2) & (ech['d231'].isnull()), 'd231'] = 2\n",
    "\n",
    "# Si d184 == 2 (no tiene ayuda gratuita), entonces d184_1 debe ser 0 si est vaca\n",
    "ech.loc[(ech['d184'] == 2) & (ech['d184_1'].isnull()), 'd184_1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4ebc90c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificacin de valores nulos en variables imputadas:\n",
      "d229      28066\n",
      "d230      28066\n",
      "d231      28066\n",
      "d232      28066\n",
      "d184_1    28066\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificacin de valores nulos despus de imputacin corregida\n",
    "cols_verificar = ['d229', 'd230', 'd231', 'd232', 'd184_1']\n",
    "\n",
    "print(\"Verificacin de valores nulos en variables imputadas:\")\n",
    "print(ech[cols_verificar].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b606a1",
   "metadata": {},
   "source": [
    "Si f269 TRABAJO LA SEMANA ANTERIOR es 2 = No imputamos las siguientes variables tambien como 2 = No:\n",
    "- f290 USO DE PC, TELFONO INTELIGENTE O TABLETA PARA TRABAJAR\n",
    "- f291_a OTRO LUGAR DIFERENTE AL HOGAR, LOCAL PROPIO U OFICINA O INSTALACIN DEL CLIENTE\n",
    "- f291_b TRABAJO EN UN LUGAR DIFERENTE AL HOGAR O AL LUGAR HABITUAL DE TRABAJO\n",
    "- f292 TRABAJO REALIZADO FUERA DE SUS PROPIAS INSTALACIONES\n",
    "- f295 TRABAJO SEMANAL EN 2 LUGARES DIFRENTES A LAS INSTALACIONES DEL EMPLEADOR/A O PROPIO LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fd0ab55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_f269 = ['f290', 'f291_a', 'f291_b', 'f292', 'f293', 'f295']\n",
    "for col in cols_f269:\n",
    "    ech.loc[(ech['f269'] == 2) & (ech[col].isnull()), col] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5368ec5",
   "metadata": {},
   "source": [
    "Unificacion de variables d181 con d181_b y d184 con d184_b:\n",
    "\n",
    "- d181 y d181_b miden lo mismo (\"personas pagas para tareas domsticas o de cuidados\"), pero en distintos semestres.\n",
    "- d184 y d184_b tambin miden lo mismo (\"ayuda gratuita de familiares fuera del hogar\").\n",
    "- Ambas parejas de variables tienen 50% de valores nulos complementarios, por lo que es totalmente vlido consolidarlas en una nueva variable que conserve el significado original.\n",
    "\n",
    "Para cada par, usamos el valor no nulo que exista.\n",
    "\n",
    "Si los dos valores son nulos (por ejemplo, por no aplicar), la variable consolidada tambin quedar nula.\n",
    "\n",
    "Primero recodificamos d181_b y d184_b a binario, ya que toman valores 1, 2 y 3 para Si y 1 y 2 para Si respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "52650378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ceros en d181: 260\n",
      "Cantidad de ceros en d184: 260\n"
     ]
    }
   ],
   "source": [
    "# Contamos cuntos ceros hay en d181 y d184 antes de imputar\n",
    "n_d181_ceros = (ech['d181'] == 0).sum()\n",
    "n_d184_ceros = (ech['d184'] == 0).sum()\n",
    "\n",
    "print(f\"Cantidad de ceros en d181: {n_d181_ceros}\")\n",
    "print(f\"Cantidad de ceros en d184: {n_d184_ceros}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc10775",
   "metadata": {},
   "source": [
    "Imputacin de valores 0 en d181 y d184:\n",
    "\n",
    "Durante el procesamiento inicial, se imputaron valores 0 en d181 y d184 en casos donde no se respondi la pregunta sobre servicio domstico o ayuda gratuita.\n",
    "\n",
    "Estos 0 representan casos no aplicables (por ejemplo, hogares sin servicio domstico), por lo tanto, decidimos reemplazarlos por el valor 2 (No) antes de crear las columnas unificadas d181_unificado y d184_unificado.\n",
    "\n",
    "Esto evita que la unificacin resulte en valores faltantes injustificados y preserva la lgica del cuestionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6ee6c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos 0 por 2 (No aplica) en las variables d181 y d184 antes de unificarlas\n",
    "ech.loc[ech['d181'] == 0, 'd181'] = 2\n",
    "ech.loc[ech['d184'] == 0, 'd184'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ecee6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recodificar d181_b a binario (1 = S, 2 = No)\n",
    "d181_b_bin = ech['d181_b'].map({1: 1, 2: 1, 3: 1, 4: 2})\n",
    "\n",
    "# Unificar d181 y d181_b\n",
    "ech['d181_unificado'] = ech['d181'].combine_first(d181_b_bin)\n",
    "\n",
    "# Recodificar d184_b a binario (1 = S, 2 = No)\n",
    "d184_b_bin = ech['d184_b'].map({1: 1, 2: 1, 3: 2})\n",
    "\n",
    "# Unificar d184 y d184_b\n",
    "ech['d184_unificado'] = ech['d184'].combine_first(d184_b_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "172171cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en columnas unificadas:\n",
      "d181_unificado    0\n",
      "d184_unificado    0\n",
      "dtype: int64\n",
      "\n",
      "Valores nicos en d181_unificado:\n",
      "d181_unificado\n",
      "1.0     4508\n",
      "2.0    51415\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores nicos en d184_unificado:\n",
      "d184_unificado\n",
      "1.0     2371\n",
      "2.0    53552\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proporcin de respuestas (1 = S, 2 = No):\n",
      "d181_unificado:\n",
      "d181_unificado\n",
      "2.0    91.94%\n",
      "1.0     8.06%\n",
      "Name: proportion, dtype: object\n",
      "d184_unificado:\n",
      "d184_unificado\n",
      "2.0    95.76%\n",
      "1.0     4.24%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cdigo de validacin para las columnas unificadas\n",
    "# Validar que no haya valores nulos\n",
    "print(\"Valores nulos en columnas unificadas:\")\n",
    "print(ech[['d181_unificado', 'd184_unificado']].isnull().sum())\n",
    "\n",
    "# Validar que solo haya valores 1 o 2\n",
    "print(\"\\nValores nicos en d181_unificado:\")\n",
    "print(ech['d181_unificado'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "print(\"\\nValores nicos en d184_unificado:\")\n",
    "print(ech['d184_unificado'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "# Validar proporcin de respuestas \"S\" y \"No\"\n",
    "print(\"\\nProporcin de respuestas (1 = S, 2 = No):\")\n",
    "print(\"d181_unificado:\")\n",
    "print(ech['d181_unificado'].value_counts(normalize=True).map(lambda x: f\"{x:.2%}\"))\n",
    "\n",
    "print(\"d184_unificado:\")\n",
    "print(ech['d184_unificado'].value_counts(normalize=True).map(lambda x: f\"{x:.2%}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e35430",
   "metadata": {},
   "source": [
    "Esto implica que solo 8 de cada 100 hogares pagan a una persona por tareas domsticas o cuidados. Esto es completamente razonable en el contexto uruguayo, dado que este tipo de contratacin suele estar concentrada en hogares de mayor poder adquisitivo o con necesidades especficas de cuidado. Son coherentes con lo esperado para la poblacin general en una encuesta nacional.\n",
    "\n",
    "Menos del 5% de los hogares reciben ayuda gratuita de otros familiares que no integran el hogar. Tambin es razonable. La solidaridad familiar informal existe, pero no es una prctica diaria ni generalizada como para que aparezca en un alto porcentaje en una encuesta estructurada.\n",
    "\n",
    "Ambas proporciones:\n",
    "- Son coherentes con lo esperado para la poblacin general en una encuesta nacional.\n",
    "- Validan que la lgica de unificacin y recodificacin fue correcta.\n",
    "- No presentan valores anmalos o distribuciones sesgadas artificialmente (como hubiera pasado si imputaras todo como 2 sin justificacin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "43b039a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas originales si ya no las necesitamos\n",
    "ech.drop(columns=['d181', 'd181_b', 'd184', 'd184_b'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1a8648d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 variables correlacionadas con el ingreso (YDA):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HT11        0.998246\n",
       "YDA_SVL     0.991424\n",
       "YSVL        0.988927\n",
       "log_YDA     0.822117\n",
       "d8_3        0.663271\n",
       "eg_ps2      0.599231\n",
       "HT13        0.584917\n",
       "d14         0.573026\n",
       "d21_15_4    0.558708\n",
       "PT1         0.515934\n",
       "Name: YDA, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VEMOS CORRELACION CON LA VARIABLE OBJETIVO\n",
    "# Seleccionamos solo las columnas numricas para evitar errores\n",
    "ech_numericas = ech.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculamos correlaciones solo sobre esas columnas\n",
    "correlaciones = ech_numericas.corr()[target].drop(target).sort_values(ascending=False)\n",
    "\n",
    "# Mostramos resultados\n",
    "print(\"\\nTop 10 variables correlacionadas con el ingreso (YDA):\")\n",
    "display(correlaciones.head(10))\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=correlaciones.head(10).values, y=correlaciones.head(10).index)\n",
    "plt.title(\"Top 10 variables correlacionadas con el ingreso\")\n",
    "plt.xlabel(\"Correlacin\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fc772",
   "metadata": {},
   "source": [
    "Verificando el diccionario, las variables correlacionadas con el ingreso son:\n",
    "- HT11: INGRESO TOTAL DEL HOGAR CON VALOR LOCATIVO SIN SERVICIO DOMSTICO\n",
    "- YDA_SVL: INGRESO DISPONIBLE AJUSTADO (SIN VALOR LOCATIVO)\n",
    "- YSVL: INGRESO TOTAL DEL HOGAR SIN VALOR LOCATIVO SIN SERVICIO DOMSTICO\n",
    "- d8_3: TENENCIA DE LA VIVIENDA > Monto del alquiler (efectivamente pagado o estimado)\n",
    "- eg_ps2: MONTO MNIMO MENSUAL REQUERIDO PARA SATISFACER LAS NECESIDADES BSICAS\n",
    "- HT13: VALOR LOCATIVO\n",
    "- d14: CANTIDAD DE BAOS\n",
    "- d21_15_4: ELEMENTOS DE CONFORT > Cantidad de microcomputadores que no son del Plan Ceibal\n",
    "- PT1: TOTAL DE INGRESOS PERSONALES\n",
    "- d21_14_1: ELEMENTOS DE CONFORT > Cantidad de equipos de aire acondicionado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a26385",
   "metadata": {},
   "source": [
    "Profundizamos en la correlacion con la variable objetivo:\n",
    "- Usar correlacin de Pearson para variables numricas  detectar alta correlacin con YDA o log_YDA.\n",
    "- Usar feature importance rpida con un modelo tipo RandomForestRegressor para detectar tambin correlacin no lineal o relaciones ms complejas.\n",
    "- Generar un listado de columnas candidatas a eliminar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda5c83",
   "metadata": {},
   "source": [
    "Buscamos detectar variables muy correlacionadas con nuestra variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f4c3bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BLOQUE 0 - Preparacin\n",
    "# =========================\n",
    "df_corr_rf = ech.copy()  # Usa tu DataFrame original con las 535 variables\n",
    "target_var = 'YDA'\n",
    "\n",
    "# Eliminar filas donde el target sea NaN\n",
    "df_corr_rf = df_corr_rf[df_corr_rf[target_var].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9dcde780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut603933\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\ut603933\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Correlacin de Pearson con YDA (top 20):\n",
      "HT11              0.998246\n",
      "YDA_SVL           0.991424\n",
      "YSVL              0.988927\n",
      "log_YDA           0.822117\n",
      "d8_3              0.663271\n",
      "eg_ps2            0.599231\n",
      "HT13              0.584917\n",
      "d14               0.573026\n",
      "d21_15_4          0.558708\n",
      "PT1               0.515934\n",
      "d21_14_1          0.487742\n",
      "PT4               0.477747\n",
      "d21_18_1          0.464888\n",
      "PT2               0.450271\n",
      "d21_5_1           0.426292\n",
      "d9                0.403760\n",
      "d229              0.402709\n",
      "d21_21           -0.400243\n",
      "d181_unificado   -0.400131\n",
      "d231              0.399031\n",
      "dtype: float64\n",
      "\n",
      "Variables con correlacin |r| >= 0.85:\n",
      "['HT11', 'YDA_SVL', 'YSVL']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# BLOQUE 1 - Correlacin\n",
    "# =========================\n",
    "# Selecciona variables numricas reales (excluyendo el target)\n",
    "num_vars = df_corr_rf.select_dtypes(include=[np.number]).columns.drop(target_var, errors='ignore')\n",
    "\n",
    "correlaciones = df_corr_rf[num_vars].corrwith(df_corr_rf[target_var]).sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n Correlacin de Pearson con YDA (top 20):\")\n",
    "print(correlaciones.head(20))\n",
    "\n",
    "# Variables con correlacin alta (umbral configurable, ej. >= 0.85)\n",
    "umbral_corr = 0.85\n",
    "vars_corr_altas = correlaciones[correlaciones.abs() >= umbral_corr].index.tolist()\n",
    "\n",
    "print(f\"\\nVariables con correlacin |r| >= {umbral_corr}:\")\n",
    "print(vars_corr_altas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f1855eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Entrenando Random Forest para evaluar importancia de variables...\n",
      "\n",
      " Importancia segn Random Forest (top 20):\n",
      "log_YDA       0.932538\n",
      "HT11          0.031985\n",
      "YDA_SVL       0.018750\n",
      "YSVL          0.013839\n",
      "h158_1        0.000369\n",
      "li_06         0.000314\n",
      "li_17         0.000209\n",
      "d230          0.000146\n",
      "lp_17         0.000130\n",
      "MTO_VACAS     0.000127\n",
      "ccz           0.000109\n",
      "MTO_CABALL    0.000091\n",
      "MTO_OVEJA     0.000083\n",
      "d21_15_4      0.000079\n",
      "W_SEM         0.000070\n",
      "HT13          0.000064\n",
      "lp_06         0.000056\n",
      "W_ANO         0.000054\n",
      "f80           0.000054\n",
      "ID            0.000044\n",
      "dtype: float64\n",
      "\n",
      "Variables con importancia >= 0.05:\n",
      "['log_YDA']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# =========================\n",
    "# BLOQUE 2 - Importancia con Random Forest\n",
    "# =========================\n",
    "if len(num_vars) > 0:\n",
    "    print(\"\\n Entrenando Random Forest para evaluar importancia de variables...\")\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    rf.fit(df_corr_rf[num_vars], df_corr_rf[target_var])\n",
    "\n",
    "    importancias_rf = pd.Series(rf.feature_importances_, index=num_vars).sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\n Importancia segn Random Forest (top 20):\")\n",
    "    print(importancias_rf.head(20))\n",
    "\n",
    "    # Variables con importancia muy alta (ej. >= 0.05)\n",
    "    umbral_importancia = 0.05\n",
    "    vars_importantes_rf = importancias_rf[importancias_rf >= umbral_importancia].index.tolist()\n",
    "\n",
    "    print(f\"\\nVariables con importancia >= {umbral_importancia}:\")\n",
    "    print(vars_importantes_rf)\n",
    "\n",
    "else:\n",
    "    print(\"\\n No hay variables numricas para entrenar el Random Forest.\")\n",
    "    importancias_rf = pd.Series(dtype=float)\n",
    "    vars_importantes_rf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cd4e4227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total variables candidatas a eliminar por alta relacin con YDA: 4\n",
      "['HT11', 'YSVL', 'YDA_SVL', 'log_YDA']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# BLOQUE 3 - Unificacin de listas\n",
    "# =========================\n",
    "vars_a_eliminar = list(set(vars_corr_altas + vars_importantes_rf))\n",
    "print(f\"\\n Total variables candidatas a eliminar por alta relacin con {target_var}: {len(vars_a_eliminar)}\")\n",
    "print(vars_a_eliminar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fe7b7",
   "metadata": {},
   "source": [
    "Preprocesamiento de variables categoricas dicotomicas, nominales u ordinales y numericas discretas o continuas. \n",
    "\n",
    "No incluimos:\n",
    "- HT11: INGRESO TOTAL DEL HOGAR CON VALOR LOCATIVO SIN SERVICIO DOMSTICO\n",
    "- YSVL: INGRESO TOTAL DEL HOGAR SIN VALOR LOCATIVO SIN SERVICIO DOMSTICO\n",
    "- YDA_SVL: INGRESO DISPONIBLE AJUSTADO (SIN VALOR LOCATIVO)\n",
    "- YDA: INGRESO DISPONIBLE AJUSTADO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2e3f17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAMOS LIBRERIAS\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "361eb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== PASO 1: Definir las listas de variables segn nuestro Excel ======\n",
    "\n",
    "dicotomicas = ['c5_2', 'c5_10', 'c5_11', 'c5_12', 'c5_13', 'c6', 'd8_4', 'd15', 'd21_1', 'd21_2', 'd21_3', 'd21_6', 'd21_4', 'd21_5', 'd21_20', 'd21_7', 'd21_10', 'd21_11', 'd21_12', 'd21_13', 'd21_14', 'd21_15', 'd21_15_1', 'd21_15_3', 'd21_15_5', 'd21_16', 'd21_16_1', 'd21_16_2', 'd21_21', 'd21_17', 'd21_18', 'd21_19', 'd181_unificado', 'd231', 'd184_unificado', 'e26', 'e29_1', 'e29_2', 'e29_3', 'e29_4', 'e29_5', 'e31', 'e32', 'e33', 'e185', 'e38', 'e45_4_1_cv', 'e45_cvb', 'e46_cv', 'e48', 'e581a', 'e582', 'e197_1', 'e201_1a', 'e201_1b', 'e201_1c', 'e201_1d', 'e51_6b', 'e215_1', 'e218_1', 'e221_1', 'e224_1', 'e559', 'e584', 'e59', 'f269', 'f270', 'f271', 'f272', 'f274', 'f276', 'f82', 'f84', 'f278', 'f280_1', 'f280_2', 'f280_3', 'f281_1', 'f281_2', 'f281_3', 'f281_4', 'f75', 'f81', 'f266_2', 'f267', 'f268', 'f289', 'f290', 'f291_a', 'f291_b', 'f292', 'f293', 'f294', 'f295', 'f96', 'f99', 'f100', 'f102', 'f298', 'f299', 'f114', 'f115', 'f300', 'f116', 'f117', 'f123', 'f124_1', 'f124_2', 'f124_3', 'f124_5', 'g250_1', 'g250_2', 'g250_3', 'g250_4', 'g250_5', 'g127', 'g128', 'g129', 'g129_1', 'g130', 'g131', 'g133', 'g_st_1', 'g251_1', 'g251_2', 'g251_3', 'g251_4', 'g251_5', 'g135', 'g136', 'g137', 'g137_1', 'g138', 'g139', 'g141', 'g_itnd_1', 'g142', 'g_itnd_2', 'g144', 'g_it_1', 'g_it_2', 'g149', 'g149_1', 'g150', 'g255', 'g152', 'g153', 'g258', 'g154', 'h155', 'h156', 'h272', 'h273', 'h274', 'h252', 'h159', 'h160', 'h161', 'h162', 'h227', 'h269', 'h167_2', 'h167_3', 'h167_4', 'h169', 'h271', 'h171', 'h172', 'h173', 'i228', 'i259', 'eg_ps1', 'SUBEMPLEO', 'pobre06', 'indig06', 'pobre_multi', 'pobre17', 'indig17']\n",
    "\n",
    "nominales = ['dpto', 'secc', 'ESTRED13', 'LOC_AGR_13', 'c1', 'd8_1', 'd11', 'd12', 'e557', 'e29_6', 'e30', 'e35', 'e36', 'e37', 'e234_2', 'e39', 'e235_2', 'e236', 'e236_4', 'e45_cv', 'e45_1_1_cv', 'e45_2_1_cv', 'e45_3_1_cv', 'e45_cva', 'e47_cv', 'e190', 'e49', 'e581', 'e209_1', 'e202', 'e214_1', 'e217_1', 'e220_1', 'e223_1', 'e226_1', 'e246', 'f273', 'f69', 'f69_1', 'f277', 'f71_2', 'f72_2', 'f73', 'f83', 'f278_a', 'f279', 'f76_2', 'f266', 'f266_1', 'f305', 'f306', 'f78', 'f80', 'f285', 'f286', 'f287', 'f288', 'f90_2', 'f91_2', 'f92', 'f97', 'f94', 'f101', 'f103', 'f104', 'f110', 'f111', 'f108', 'f301', 'f106', 'f122', 'f119_2', 'f120_2', 'f121', 'f125', 'g132', 'g140', 'g_itnd_3', 'g256', 'POBPCOAC', 'USO_RRAA']\n",
    "\n",
    "ordinales = ['region', 'REGION_4', 'c2', 'c3', 'c4', 'd13', 'd16', 'd18', 'd260', 'd19', 'd20', 'e579', 'e583', 'e579a', 'f275', 'f283', 'f77', 'f93', 'h167_1', 'eg_ahorro', 'eg_ps3', 'eg_ps4', 'eg_ps5', 'eg_ps6', 'eg_ps7', 'eg_ps8']\n",
    "\n",
    "numericas_discretas = ['ID', 'nper', 'anio', 'mes', 'GR', 'ccz', 'barrio', 'c6_1', 'd9', 'd10', 'd14', 'd21_4_1', 'd21_5_1', 'd21_14_1', 'd21_15_2', 'd21_15_4', 'd21_15_6', 'd21_18_1', 'd21_19_1', 'd229', 'd230', 'd232', 'd184_1', 'd23', 'd24', 'd25', 'e27', 'e31_1', 'e32_1', 'e34', 'e186_1', 'e186_2', 'e186_3', 'e186_4', 'e37_2', 'e38_1', 'e39_2', 'e236_2', 'e45_1_1_1_cv', 'e45_2_1_1_cv', 'e45_3_1_1_cv', 'e45_4_1_1_cv', 'e47_1_cv', 'e49a', 'e582_1', 'e582_2', 'e582_3', 'e51_2', 'e51_3', 'e51_4_a', 'e51_4_b', 'e51_5', 'e51_6', 'e51_6a', 'e51_8', 'e51_9', 'e51_10', 'e51_11', 'e559_1', 'e559_2', 'e247', 'f70', 'f80_2', 'f284_1', 'f284_2', 'f284_3', 'f284_4', 'f284_5', 'f284_6', 'f284_7', 'f85', 'f307', 'f308', 'f94_2', 'f296_1', 'f296_2', 'f296_3', 'f296_4', 'f296_5', 'f296_6', 'f296_7', 'f98', 'f297', 'f113', 'f118_1', 'f118_2', 'g127_1', 'g127_2', 'g132_1', 'g132_2', 'g132_3', 'g135_1', 'g135_2', 'g140_1', 'g140_2', 'g140_3', 'g151_6', 'g151_3', 'g151_4', 'h272_1', 'h273_1', 'h274_1', 'h274_2', 'h274_3', 'h158_1', 'h158_2', 'h171_2', 'HT19']\n",
    "\n",
    "numericas_continuas = ['d8_2', 'd8_3', 'e584_1', 'g_id_1', 'g_id_2', 'g_id_3', 'g_id_1a', 'g_id_2a', 'g_id_3a', 'g126_1', 'g126_2', 'g126_3', 'g126_4', 'g126_5', 'g126_6', 'g126_7', 'g126_8', 'g127_3', 'g128_1', 'g129_2', 'g130_1', 'g131_1', 'g133_1', 'g133_2', 'g134_1', 'g134_2', 'g134_3', 'g134_4', 'g134_5', 'g134_6', 'g134_7', 'g134_8', 'g135_3', 'g136_1', 'g137_2', 'g138_1', 'g139_1', 'g141_1', 'g141_2', 'g143', 'g144_1', 'g144_2_1', 'g144_2_2', 'g144_2_3', 'g144_2_4', 'g144_2_5', 'g259', 'g148_1_1', 'g148_1_2', 'g148_1_3', 'g148_1_5', 'g148_1_6', 'g148_1_7', 'g148_1_8', 'g148_1_9', 'g148_1_10', 'g148_1_11', 'g148_1_12', 'g148_2_1', 'g148_2_2', 'g148_2_3', 'g148_2_5', 'g148_2_6', 'g148_2_7', 'g148_2_8', 'g148_2_9', 'g148_2_10', 'g148_2_11', 'g148_2_12', 'g148_3', 'g148_4', 'g148_5_1', 'g148_5_2', 'g257', 'g153_1', 'g153_2', 'g258_1', 'g154_1', 'h155_1', 'h156_1', 'h252_1', 'h160_1', 'h160_2', 'h163_1', 'h163_2', 'h164', 'h165', 'h166', 'h269_1', 'h167_1_3', 'h167_2_3', 'h167_3_3', 'h167_4_3', 'h170_3', 'h271_1', 'h171_1', 'h172_1', 'h173_1', 'i174', 'i175', 'eg_ps2', 'MTO_CUOTA', 'MTO_EMER', 'MTO_HOGCON', 'MTO_DESAY', 'MTO_ALMUE', 'MTO_VACAS', 'MTO_OVEJA', 'MTO_CABALL', 'INDACELIAC', 'INDAEMER', 'PT1', 'PT2', 'PT4', 'HT13', 'YHOG', 'AFAM_H_DEC', 'AFAM_H', 'TUS_H_DEC', 'TUS_H', 'lp_06', 'li_06', 'lp_17', 'li_17', 'monto_imput_UTE', 'monto_imput_GAS', 'monto_imput_OSE', 'H_FONASA', 'montoGAS_RRAA', 'montoUTE_RRAA', 'montoOSE_RRAA', 'W_TRI', 'W_SEM', 'W_ANO']\n",
    "\n",
    "# Variable objetivo\n",
    "target = 'YDA'\n",
    "ech['log_YDA'] = np.log1p(ech[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a367e4",
   "metadata": {},
   "source": [
    "No incluimos 'nom_dpto' ni 'NOM_LOC_AGR_13' que habiamos puesto originalmente en el grupo de nominales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc298b5",
   "metadata": {},
   "source": [
    "No se incluyeron las siguientes variables porque si bien aparecen en el Excel no aparecen en el dataframe:\n",
    "\n",
    "Dicotomicas:\n",
    "- h2_cv: HOGAR CONTINA RESIDIENDO EN LA MISMA VIVIENDA\n",
    "- c5_1, c5_3 a c5_9: PROBLEMAS DE LA VIVIENDA\n",
    "- e0_cv: NUEVO MIEMBRO DEL HOGAR\n",
    "- e01_cv: NUEVO MIEMBRO DEPENDE DEL FONDO DE ALIMENTACIN\n",
    "- e1_cv: MIEMBRO CONTINA RESIDIENDO EN EL HOGAR\n",
    "- f304: MANTIENE MISMO TRABAJO PRINCIPAL DECLARADO EN ENTREVISTA ANTERIOR\n",
    "- f302: REALIZA LAS MISMAS TAREAS\n",
    "- f303: EL ESTABLECIMIENTO CONTINUA REALIZANDO LAS MISMAS TAREAS\n",
    "- f311: MANTIENE MISMO TRABAJO SECUNDARIO DECLARADO EN ENTREVISTA ANTERIOR\n",
    "- f309: REALIZA LAS MISMAS TAREAS\n",
    "- f310: EL ESTABLECIMIENTO CONTINUA REALIZANDO LAS MISMAS TAREAS\n",
    "- INFORMAL: TRABAJADOR INFORMAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143030cb",
   "metadata": {},
   "source": [
    "Algunas variables toman valores nan luego de recodificar como variables dicotomicas. Vemos que valores toman.\n",
    "\n",
    "El problema es que en el dataset hay valores que no son ni 1 ni 2 en algunas variables dicotmicas y cualquier valor diferente de 1 o 2 (por ejemplo, NaN, 9, 3, o cualquier otro cdigo especial) se transforma automticamente en NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "64674146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nicos en 'c5_2':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'c5_10':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'c5_11':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'c5_12':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'c5_13':\n",
      "[nan  2.  1.]\n",
      "\n",
      "Valores nicos en 'c6':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd8_4':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd15':\n",
      "[1 2 0]\n",
      "\n",
      "Valores nicos en 'd21_1':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_2':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_3':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_6':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_4':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_5':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_20':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_7':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_10':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_11':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_12':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_13':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_14':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_15':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_15_1':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'd21_15_3':\n",
      "[1 0 2]\n",
      "\n",
      "Valores nicos en 'd21_15_5':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'd21_16':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_16_1':\n",
      "[1 0 2]\n",
      "\n",
      "Valores nicos en 'd21_16_2':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'd21_21':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_17':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'd21_18':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd21_19':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'd181_unificado':\n",
      "[2. 1.]\n",
      "\n",
      "Valores nicos en 'd231':\n",
      "[ 0.  2.  1. nan]\n",
      "\n",
      "Valores nicos en 'd184_unificado':\n",
      "[2. 1.]\n",
      "\n",
      "Valores nicos en 'h155':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h156':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h272':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h273':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h274':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h252':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h159':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h160':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'h161':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h162':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'h227':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h269':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'h167_2':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h167_3':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h167_4':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h169':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h271':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h171':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h172':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'h173':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'i228':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'i259':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'eg_ps1':\n",
      "[1 2 0]\n",
      "\n",
      "Valores nicos en 'pobre06':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'indig06':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'pobre17':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'indig17':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'pobre_multi':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'e26':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'e29_1':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'e29_2':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'e29_3':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'e29_4':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'e29_5':\n",
      "[2 1]\n",
      "\n",
      "Valores nicos en 'e31':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e32':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e33':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'e185':\n",
      "[1 0 2]\n",
      "\n",
      "Valores nicos en 'e38':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'e45_4_1_cv':\n",
      "[1 0 2]\n",
      "\n",
      "Valores nicos en 'e45_cvb':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e46_cv':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'e48':\n",
      "[1 2]\n",
      "\n",
      "Valores nicos en 'e581a':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'e582':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e197_1':\n",
      "[1 0 2]\n",
      "\n",
      "Valores nicos en 'e201_1b':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e201_1c':\n",
      "[1 0 2]\n",
      "\n",
      "Valores nicos en 'e201_1d':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e51_6b':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'e215_1':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'e218_1':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e221_1':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'e224_1':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'e559':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'e584':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'e59':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'f269':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'f270':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'f271':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f272':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f274':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f276':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'f82':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f84':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f278':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f280_1':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f280_2':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f280_3':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f281_1':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f281_2':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f281_3':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f281_4':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f75':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f81':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f266_2':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f267':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f268':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f289':\n",
      "[ 0.  1.  2. nan]\n",
      "\n",
      "Valores nicos en 'f290':\n",
      "[ 0.  1.  2. nan]\n",
      "\n",
      "Valores nicos en 'f291_a':\n",
      "[ 0.  2.  1. nan]\n",
      "\n",
      "Valores nicos en 'f291_b':\n",
      "[ 0.  2.  1. nan]\n",
      "\n",
      "Valores nicos en 'f292':\n",
      "[ 0.  2.  1. nan]\n",
      "\n",
      "Valores nicos en 'f293':\n",
      "[ 0.  1.  2. nan]\n",
      "\n",
      "Valores nicos en 'f294':\n",
      "[ 0.  1.  2. nan]\n",
      "\n",
      "Valores nicos en 'f295':\n",
      "[ 0.  1.  2. nan]\n",
      "\n",
      "Valores nicos en 'f96':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f99':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f100':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f102':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f298':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'f299':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'f114':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f115':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'f300':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'f116':\n",
      "[1 0 2]\n",
      "\n",
      "Valores nicos en 'f117':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'f123':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'f124_1':\n",
      "[1 2 0]\n",
      "\n",
      "Valores nicos en 'f124_2':\n",
      "[1 2 0]\n",
      "\n",
      "Valores nicos en 'f124_3':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'f124_5':\n",
      "[1 2 0]\n",
      "\n",
      "Valores nicos en 'g250_1':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g250_2':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'g250_5':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g250_3':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g250_4':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g127':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g128':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g129':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g129_1':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'g130':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g131':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g133':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g_st_1':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g251_1':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g251_2':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'g251_5':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g251_3':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g251_4':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g135':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g136':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g137':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g137_1':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'g138':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g139':\n",
      "[0 2 1]\n",
      "\n",
      "Valores nicos en 'g141':\n",
      "[0 2]\n",
      "\n",
      "Valores nicos en 'g_itnd_1':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'g_itnd_2':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'g144':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'g_it_1':\n",
      "[1 2 0]\n",
      "\n",
      "Valores nicos en 'g_it_2':\n",
      "[1 2 0]\n",
      "\n",
      "Valores nicos en 'g149':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'g149_1':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'g150':\n",
      "[3 0 1]\n",
      "\n",
      "Valores nicos en 'g255':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'g152':\n",
      "[0 1 2]\n",
      "\n",
      "Valores nicos en 'g153':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'g258':\n",
      "[2 1 0]\n",
      "\n",
      "Valores nicos en 'g154':\n",
      "[2 0 1]\n",
      "\n",
      "Valores nicos en 'SUBEMPLEO':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'indig06':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'pobre17':\n",
      "[0 1]\n",
      "\n",
      "Valores nicos en 'indig17':\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "variables_a_explorar = ['c5_2', 'c5_10', 'c5_11', 'c5_12', 'c5_13', 'c6', 'd8_4', 'd15', 'd21_1', 'd21_2', 'd21_3', 'd21_6', 'd21_4', 'd21_5', 'd21_20', 'd21_7', 'd21_10', 'd21_11', 'd21_12', 'd21_13', 'd21_14', 'd21_15', 'd21_15_1', 'd21_15_3', 'd21_15_5', 'd21_16', 'd21_16_1', 'd21_16_2', 'd21_21', 'd21_17', 'd21_18', 'd21_19', 'd181_unificado', 'd231', 'd184_unificado', 'h155', 'h156', 'h272', 'h273', 'h274', 'h252', 'h159', 'h160', 'h161', 'h162', 'h227', 'h269', 'h167_2', 'h167_3', 'h167_4', 'h169', 'h271', 'h171', 'h172', 'h173', 'i228', 'i259', 'eg_ps1', 'pobre06', 'indig06', 'pobre17', 'indig17', 'pobre_multi', 'e26', 'e29_1', 'e29_2', 'e29_3', 'e29_4', 'e29_5', 'e31', 'e32', 'e33', 'e185', 'e38', 'e45_4_1_cv', 'e45_cvb', 'e46_cv', 'e48', 'e581a', 'e582', 'e197_1', 'e201_1b', 'e201_1c', 'e201_1d', 'e51_6b', 'e215_1', 'e218_1', 'e221_1', 'e224_1', 'e559', 'e584', 'e59', 'f269', 'f270', 'f271', 'f272', 'f274', 'f276', 'f82', 'f84', 'f278', 'f280_1', 'f280_2', 'f280_3', 'f281_1', 'f281_2', 'f281_3', 'f281_4', 'f75', 'f81', 'f266_2', 'f267', 'f268', 'f289', 'f290', 'f291_a', 'f291_b', 'f292', 'f293', 'f294', 'f295', 'f96', 'f99', 'f100', 'f102', 'f298', 'f299', 'f114', 'f115', 'f300', 'f116', 'f117', 'f123', 'f124_1', 'f124_2', 'f124_3', 'f124_5', 'g250_1', 'g250_2', 'g250_5', 'g250_3', 'g250_4', 'g127', 'g128', 'g129', 'g129_1', 'g130', 'g131', 'g133', 'g_st_1', 'g251_1', 'g251_2', 'g251_5', 'g251_3', 'g251_4', 'g135', 'g136', 'g137', 'g137_1', 'g138', 'g139', 'g141', 'g_itnd_1', 'g_itnd_2', 'g144', 'g_it_1', 'g_it_2', 'g149', 'g149_1', 'g150', 'g255', 'g152', 'g153', 'g258', 'g154', 'SUBEMPLEO', 'indig06', 'pobre17', 'indig17']\n",
    "\n",
    "for col in variables_a_explorar:\n",
    "    if col in ech.columns:\n",
    "        print(f\"\\nValores nicos en '{col}':\")\n",
    "        print(ech[col].unique())\n",
    "    else:\n",
    "        print(f\"\\nLa columna '{col}' no est en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c3d27e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c5_2: [0 1]\n",
      "c5_10: [0 1]\n",
      "c5_11: [0 1]\n",
      "c5_12: [0 1]\n",
      "c5_13: [0 1]\n",
      "c6: [1 0]\n",
      "d8_4: [0 1]\n",
      "d15: [1 0]\n",
      "d21_1: [1 0]\n",
      "d21_2: [0 1]\n",
      "d21_3: [1 0]\n",
      "d21_6: [0 1]\n",
      "d21_4: [0 1]\n",
      "d21_5: [1 0]\n",
      "d21_20: [0 1]\n",
      "d21_7: [1 0]\n",
      "d21_10: [1 0]\n",
      "d21_11: [0 1]\n",
      "d21_12: [0 1]\n",
      "d21_13: [1 0]\n",
      "d21_14: [0 1]\n",
      "d21_15: [1 0]\n",
      "d21_15_1: [0 1]\n",
      "d21_15_3: [1 0]\n",
      "d21_15_5: [0 1]\n",
      "d21_16: [1 0]\n",
      "d21_16_1: [1 0]\n",
      "d21_16_2: [0 1]\n",
      "d21_21: [0 1]\n",
      "d21_17: [1 0]\n",
      "d21_18: [0 1]\n",
      "d21_19: [0 1]\n",
      "d181_unificado: [0 1]\n",
      "d231: [0 1]\n",
      "d184_unificado: [0 1]\n",
      "e26: [0 1]\n",
      "e29_1: [0 1]\n",
      "e29_2: [0 1]\n",
      "e29_3: [1 0]\n",
      "e29_4: [0 1]\n",
      "e29_5: [0 1]\n",
      "e31: [0 1]\n",
      "e32: [0 1]\n",
      "e33: [0 1]\n",
      "e185: [1 0]\n",
      "e38: [1 0]\n",
      "e45_4_1_cv: [1 0]\n",
      "e45_cvb: [0 1]\n",
      "e46_cv: [1 0]\n",
      "e48: [1 0]\n",
      "e581a: [0 1]\n",
      "e582: [0 1]\n",
      "e197_1: [1 0]\n",
      "e201_1a: [1 0]\n",
      "e201_1b: [0 1]\n",
      "e201_1c: [1 0]\n",
      "e201_1d: [0 1]\n",
      "e51_6b: [0 1]\n",
      "e215_1: [0 1]\n",
      "e218_1: [0 1]\n",
      "e221_1: [0 1]\n",
      "e224_1: [0 1]\n",
      "e559: [0 1]\n",
      "e584: [0 1]\n",
      "e59: [0 1]\n",
      "f269: [0 1]\n",
      "f270: [0 1]\n",
      "f271: [0 1]\n",
      "f272: [0 1]\n",
      "f274: [0 1]\n",
      "f276: [0 1]\n",
      "f82: [0 1]\n",
      "f84: [0 1]\n",
      "f278: [0 1]\n",
      "f280_1: [0 1]\n",
      "f280_2: [0 1]\n",
      "f280_3: [0 1]\n",
      "f281_1: [0 1]\n",
      "f281_2: [0 1]\n",
      "f281_3: [0 1]\n",
      "f281_4: [0 1]\n",
      "f75: [0 1]\n",
      "f81: [0 1]\n",
      "f266_2: [0 1]\n",
      "f267: [0 1]\n",
      "f268: [0 1]\n",
      "f289: [0 1]\n",
      "f290: [0 1]\n",
      "f291_a: [0 1]\n",
      "f291_b: [0 1]\n",
      "f292: [0 1]\n",
      "f293: [0 1]\n",
      "f294: [0 1]\n",
      "f295: [0 1]\n",
      "f96: [0 1]\n",
      "f99: [0 1]\n",
      "f100: [0 1]\n",
      "f102: [0 1]\n",
      "f298: [0 1]\n",
      "f299: [0 1]\n",
      "f114: [0 1]\n",
      "f115: [0 1]\n",
      "f300: [0 1]\n",
      "f116: [1 0]\n",
      "f117: [0 1]\n",
      "f123: [0 1]\n",
      "f124_1: [1 0]\n",
      "f124_2: [1 0]\n",
      "f124_3: [0 1]\n",
      "f124_5: [1 0]\n",
      "g250_1: [0 1]\n",
      "g250_2: [0 1]\n",
      "g250_3: [0 1]\n",
      "g250_4: [0 1]\n",
      "g250_5: [0 1]\n",
      "g127: [0 1]\n",
      "g128: [0 1]\n",
      "g129: [0 1]\n",
      "g129_1: [0 1]\n",
      "g130: [0 1]\n",
      "g131: [0 1]\n",
      "g133: [0 1]\n",
      "g_st_1: [0 1]\n",
      "g251_1: [0 1]\n",
      "g251_2: [0 1]\n",
      "g251_3: [0 1]\n",
      "g251_4: [0 1]\n",
      "g251_5: [0 1]\n",
      "g135: [0 1]\n",
      "g136: [0 1]\n",
      "g137: [0 1]\n",
      "g137_1: [0 1]\n",
      "g138: [0 1]\n",
      "g139: [0 1]\n",
      "g141: [0]\n",
      "g_itnd_1: [0 1]\n",
      "g142: [0. 1.]\n",
      "g_itnd_2: [0 1]\n",
      "g144: [0 1]\n",
      "g_it_1: [1 0]\n",
      "g_it_2: [1 0]\n",
      "g149: [0 1]\n",
      "g149_1: [0 1]\n",
      "g150: [0. 1.]\n",
      "g255: [0 1]\n",
      "g152: [0 1]\n",
      "g153: [0 1]\n",
      "g258: [0 1]\n",
      "g154: [0 1]\n",
      "h155: [0 1]\n",
      "h156: [0 1]\n",
      "h272: [0 1]\n",
      "h273: [0 1]\n",
      "h274: [0 1]\n",
      "h252: [0 1]\n",
      "h159: [0 1]\n",
      "h160: [0 1]\n",
      "h161: [0 1]\n",
      "h162: [0 1]\n",
      "h227: [0 1]\n",
      "h269: [0 1]\n",
      "h167_2: [0 1]\n",
      "h167_3: [0 1]\n",
      "h167_4: [0 1]\n",
      "h169: [0 1]\n",
      "h271: [0 1]\n",
      "h171: [0 1]\n",
      "h172: [0 1]\n",
      "h173: [0 1]\n",
      "i228: [0 1]\n",
      "i259: [0 1]\n",
      "eg_ps1: [1 0]\n",
      "SUBEMPLEO: [0 1]\n",
      "pobre06: [0 1]\n",
      "indig06: [0 1]\n",
      "pobre_multi: [0 1]\n",
      "pobre17: [0 1]\n",
      "indig17: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Re-codificacin de variables dicotmicas (1  1, 2  0, 0  0, NaN  0)\n",
    "for col in dicotomicas:\n",
    "    if col in ech.columns:\n",
    "        ech[col] = ech[col].map({1: 1, 2: 0, 0: 0, np.nan: 0}).fillna(0)\n",
    "    else:\n",
    "        print(f\"Advertencia: {col} no est en el DataFrame y se omite.\")\n",
    "\n",
    "# Verificacion: Deberamos ver solo [0, 1] o [1] (si la variable es constante).\n",
    "for col in dicotomicas:\n",
    "    print(f\"{col}: {ech[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc6d46",
   "metadata": {},
   "source": [
    "No se incluyeron las siguientes variables porque si bien aparecen en el Excel no aparecen en el dataframe:\n",
    "\n",
    "Nominal:\n",
    "- h4_1_cv: DEPARTAMENTO DEL NUEVO DOMICILIO\n",
    "- SIT_OCUP: SITUACIN EN LA OCUPACIN\n",
    "- SECTOR_F: TIPO DE SECTOR\n",
    "\n",
    "Ordinales: NIV_EDU: NIVEL EDUCATIVO\n",
    "\n",
    "Discretas: ronda: ?\n",
    "\n",
    "Continuas: W: PONDERADOR MENSUAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214b897",
   "metadata": {},
   "source": [
    "El preprocesamiento original no aplicaba imputacion para valores faltantes por lo que al correr los modelos daba error. Generamos un preprocesamiento mas robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7210234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape inicial de X: (55923, 527)\n"
     ]
    }
   ],
   "source": [
    "# Separar features y target\n",
    "X = ech[dicotomicas + nominales + ordinales + numericas_discretas + numericas_continuas]\n",
    "y = ech['log_YDA']\n",
    "\n",
    "print(f\" Shape inicial de X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9742b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas duplicadas: []\n"
     ]
    }
   ],
   "source": [
    "# VEMOS COLUMNAS DUPLICADAS EN X\n",
    "from collections import Counter\n",
    "\n",
    "contador_columnas = Counter(X.columns)\n",
    "columnas_duplicadas = [col for col, count in contador_columnas.items() if count > 1]\n",
    "\n",
    "print(\"Columnas duplicadas:\", columnas_duplicadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3c589130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmero de filas con al menos un NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# CONTAR FILAS CON NaN\n",
    "n_filas_nan = np.isnan(X.sum(axis=1))\n",
    "n_filas_con_nan = np.sum(n_filas_nan > 0)\n",
    "\n",
    "print(f\"Nmero de filas con al menos un NaN: {n_filas_con_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "14ca2f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmero de columnas con al menos un NaN: 5\n"
     ]
    }
   ],
   "source": [
    "# CONTAR COLUMNAS CON NaN\n",
    "n_columnas_con_nan = np.sum(np.isnan(X).any(axis=0))\n",
    "print(f\"Nmero de columnas con al menos un NaN: {n_columnas_con_nan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5d64e",
   "metadata": {},
   "source": [
    "Tenemos que ver si esos NaN se van despues del preprovesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "514c6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2 Funciones de limpieza\n",
    "# ============================================\n",
    "def eliminar_varianza_cero(df):\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    selector = VarianceThreshold(threshold=0.0)\n",
    "    selector.fit(df)\n",
    "    cols_quitar = df.columns[~selector.get_support()].tolist()\n",
    "    df_filtrado = df.drop(columns=cols_quitar)\n",
    "    return df_filtrado, cols_quitar\n",
    "\n",
    "def eliminar_correlacion_perfecta(df):\n",
    "    corr_matrix = df.corr()\n",
    "    cols_quitar = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if corr_matrix.iloc[i, j] == 1:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                cols_quitar.add(colname)\n",
    "    df_filtrado = df.drop(columns=list(cols_quitar))\n",
    "    return df_filtrado, list(cols_quitar)\n",
    "\n",
    "def eliminar_correlacion_alta(df, umbral=0.95):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    cols_quitar = [column for column in upper.columns if any(upper[column] > umbral)]\n",
    "    df_filtrado = df.drop(columns=cols_quitar)\n",
    "    return df_filtrado, cols_quitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "483bc9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape final tras limpieza: (55923, 476)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3 Aplicar limpieza sobre X (antes de split)\n",
    "# ============================================\n",
    "# Varianza cero\n",
    "X, cols_var0 = eliminar_varianza_cero(X)\n",
    "\n",
    "# Correlacin perfecta\n",
    "X, cols_corr1 = eliminar_correlacion_perfecta(X)\n",
    "\n",
    "# Correlacin alta\n",
    "X, cols_corr_high = eliminar_correlacion_alta(X, umbral=0.95)\n",
    "\n",
    "print(f\" Shape final tras limpieza: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fe5fe1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Archivo 'columnas_eliminadas.xlsx' guardado.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4 Guardar columnas eliminadas para trazabilidad\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "df_eliminadas = pd.DataFrame({\n",
    "    \"varianza_cero\": pd.Series(cols_var0),\n",
    "    \"corr_perfecta\": pd.Series(cols_corr1),\n",
    "    \"corr_alta\": pd.Series(cols_corr_high)\n",
    "})\n",
    "df_eliminadas.to_excel(\"columnas_eliminadas.xlsx\", index=False)\n",
    "print(\" Archivo 'columnas_eliminadas.xlsx' guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b42c4",
   "metadata": {},
   "source": [
    "Generamos archivos CSV con nuestro dataset depurado para luego cargarlos en el notebook de entrenamiento de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "94e72495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Archivos guardados en carpeta 'data_processed':\n",
      "- data_processed\\X_clean.csv\n",
      "- data_processed\\y_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"data_processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Guardamos X\n",
    "X.to_csv(os.path.join(output_dir, \"X_clean.csv\"), index=False)\n",
    "\n",
    "# Guardamos y como DataFrame para no perder nombre\n",
    "y_df = pd.DataFrame(y)\n",
    "y_df.to_csv(os.path.join(output_dir, \"y_clean.csv\"), index=False)\n",
    "\n",
    "print(\" Archivos guardados en carpeta 'data_processed':\")\n",
    "print(f\"- {os.path.join(output_dir, 'X_clean.csv')}\")\n",
    "print(f\"- {os.path.join(output_dir, 'y_clean.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77caf00",
   "metadata": {},
   "source": [
    "Fin del EDA. Pasamos al notebook Modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ecda6",
   "metadata": {},
   "source": [
    "Comienzo del notebook de Modelado. Borrar todo lo que esta de aca para arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3197d0",
   "metadata": {},
   "source": [
    "**Analisis de la Encuesta Continua de Hogares 2024**\n",
    "\n",
    "- Dataset: https://www4.ine.gub.uy/Anda5/index.php/catalog/767/get-microdata\n",
    "- Diccionario: https://www4.ine.gub.uy/Anda5/index.php/catalog/767/data-dictionary/F4?file_name=ECH_implantacion_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa9e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTO LIBRERIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf296f9",
   "metadata": {},
   "source": [
    "## Carga del dataset depurado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90300cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes cargados:\n",
      "X: (55923, 2846)\n",
      "y: (55923,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datasets limpios\n",
    "X = pd.read_csv(\"data_processed/X_clean.csv\")\n",
    "y = pd.read_csv(\"data_processed/y_clean.csv\").squeeze()  # .squeeze() para que sea Serie y no DataFrame\n",
    "\n",
    "print(\"Shapes cargados:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1589d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORDAMOS LOS CONJUNTOS DE VARIABLES DEFINIDOS EN EL EDA PARA HACER EL PREPROCESAMIENTO\n",
    "\n",
    "dicotomicas = ['c5_2', 'c5_10', 'c5_11', 'c5_12', 'c5_13', 'c6', 'd8_4', 'd15', 'd21_1', 'd21_2', 'd21_3', 'd21_6', 'd21_4', 'd21_5', 'd21_20', 'd21_7', 'd21_10', 'd21_11', 'd21_12', 'd21_13', 'd21_14', 'd21_15', 'd21_15_1', 'd21_15_3', 'd21_15_5', 'd21_16', 'd21_16_1', 'd21_16_2', 'd21_21', 'd21_17', 'd21_18', 'd21_19', 'd181_unificado', 'd231', 'd184_unificado', 'e26', 'e29_1', 'e29_2', 'e29_3', 'e29_4', 'e29_5', 'e31', 'e32', 'e33', 'e185', 'e38', 'e45_4_1_cv', 'e45_cvb', 'e46_cv', 'e48', 'e581a', 'e582', 'e197_1', 'e201_1a', 'e201_1b', 'e201_1c', 'e201_1d', 'e51_6b', 'e215_1', 'e218_1', 'e221_1', 'e224_1', 'e559', 'e584', 'e59', 'f269', 'f270', 'f271', 'f272', 'f274', 'f276', 'f82', 'f84', 'f278', 'f280_1', 'f280_2', 'f280_3', 'f281_1', 'f281_2', 'f281_3', 'f281_4', 'f75', 'f81', 'f266_2', 'f267', 'f268', 'f289', 'f290', 'f291_a', 'f291_b', 'f292', 'f293', 'f294', 'f295', 'f96', 'f99', 'f100', 'f102', 'f298', 'f299', 'f114', 'f115', 'f300', 'f116', 'f117', 'f123', 'f124_1', 'f124_2', 'f124_3', 'f124_5', 'g250_1', 'g250_2', 'g250_3', 'g250_4', 'g250_5', 'g127', 'g128', 'g129', 'g129_1', 'g130', 'g131', 'g133', 'g_st_1', 'g251_1', 'g251_2', 'g251_3', 'g251_4', 'g251_5', 'g135', 'g136', 'g137', 'g137_1', 'g138', 'g139', 'g141', 'g_itnd_1', 'g142', 'g_itnd_2', 'g144', 'g_it_1', 'g_it_2', 'g149', 'g149_1', 'g150', 'g255', 'g152', 'g153', 'g258', 'g154', 'h155', 'h156', 'h272', 'h273', 'h274', 'h252', 'h159', 'h160', 'h161', 'h162', 'h227', 'h269', 'h167_2', 'h167_3', 'h167_4', 'h169', 'h271', 'h171', 'h172', 'h173', 'i228', 'i259', 'eg_ps1', 'SUBEMPLEO', 'pobre06', 'indig06', 'pobre_multi', 'pobre17', 'indig17']\n",
    "\n",
    "nominales = ['dpto', 'secc', 'ESTRED13', 'LOC_AGR_13', 'c1', 'd8_1', 'd11', 'd12', 'e557', 'e29_6', 'e30', 'e35', 'e36', 'e37', 'e234_2', 'e39', 'e235_2', 'e236', 'e236_4', 'e45_cv', 'e45_1_1_cv', 'e45_2_1_cv', 'e45_3_1_cv', 'e45_cva', 'e47_cv', 'e190', 'e49', 'e581', 'e209_1', 'e202', 'e214_1', 'e217_1', 'e220_1', 'e223_1', 'e226_1', 'e246', 'f273', 'f69', 'f69_1', 'f277', 'f71_2', 'f72_2', 'f73', 'f83', 'f278_a', 'f279', 'f76_2', 'f266', 'f266_1', 'f305', 'f306', 'f78', 'f80', 'f285', 'f286', 'f287', 'f288', 'f90_2', 'f91_2', 'f92', 'f97', 'f94', 'f101', 'f103', 'f104', 'f110', 'f111', 'f108', 'f301', 'f106', 'f122', 'f119_2', 'f120_2', 'f121', 'f125', 'g132', 'g140', 'g_itnd_3', 'g256', 'POBPCOAC', 'USO_RRAA']\n",
    "\n",
    "ordinales = ['region', 'REGION_4', 'c2', 'c3', 'c4', 'd13', 'd16', 'd18', 'd260', 'd19', 'd20', 'e579', 'e583', 'e579a', 'f275', 'f283', 'f77', 'f93', 'h167_1', 'eg_ahorro', 'eg_ps3', 'eg_ps4', 'eg_ps5', 'eg_ps6', 'eg_ps7', 'eg_ps8']\n",
    "\n",
    "numericas_discretas = ['ID', 'nper', 'anio', 'mes', 'GR', 'ccz', 'barrio', 'c6_1', 'd9', 'd10', 'd14', 'd21_4_1', 'd21_5_1', 'd21_14_1', 'd21_15_2', 'd21_15_4', 'd21_15_6', 'd21_18_1', 'd21_19_1', 'd229', 'd230', 'd232', 'd184_1', 'd23', 'd24', 'd25', 'e27', 'e31_1', 'e32_1', 'e34', 'e186_1', 'e186_2', 'e186_3', 'e186_4', 'e37_2', 'e38_1', 'e39_2', 'e236_2', 'e45_1_1_1_cv', 'e45_2_1_1_cv', 'e45_3_1_1_cv', 'e45_4_1_1_cv', 'e47_1_cv', 'e49a', 'e582_1', 'e582_2', 'e582_3', 'e51_2', 'e51_3', 'e51_4_a', 'e51_4_b', 'e51_5', 'e51_6', 'e51_6a', 'e51_8', 'e51_9', 'e51_10', 'e51_11', 'e559_1', 'e559_2', 'e247', 'f70', 'f80_2', 'f284_1', 'f284_2', 'f284_3', 'f284_4', 'f284_5', 'f284_6', 'f284_7', 'f85', 'f307', 'f308', 'f94_2', 'f296_1', 'f296_2', 'f296_3', 'f296_4', 'f296_5', 'f296_6', 'f296_7', 'f98', 'f297', 'f113', 'f118_1', 'f118_2', 'g127_1', 'g127_2', 'g132_1', 'g132_2', 'g132_3', 'g135_1', 'g135_2', 'g140_1', 'g140_2', 'g140_3', 'g151_6', 'g151_3', 'g151_4', 'h272_1', 'h273_1', 'h274_1', 'h274_2', 'h274_3', 'h158_1', 'h158_2', 'h171_2', 'HT19']\n",
    "\n",
    "numericas_continuas = ['d8_2', 'd8_3', 'e584_1', 'g_id_1', 'g_id_2', 'g_id_3', 'g_id_1a', 'g_id_2a', 'g_id_3a', 'g126_1', 'g126_2', 'g126_3', 'g126_4', 'g126_5', 'g126_6', 'g126_7', 'g126_8', 'g127_3', 'g128_1', 'g129_2', 'g130_1', 'g131_1', 'g133_1', 'g133_2', 'g134_1', 'g134_2', 'g134_3', 'g134_4', 'g134_5', 'g134_6', 'g134_7', 'g134_8', 'g135_3', 'g136_1', 'g137_2', 'g138_1', 'g139_1', 'g141_1', 'g141_2', 'g143', 'g144_1', 'g144_2_1', 'g144_2_2', 'g144_2_3', 'g144_2_4', 'g144_2_5', 'g259', 'g148_1_1', 'g148_1_2', 'g148_1_3', 'g148_1_5', 'g148_1_6', 'g148_1_7', 'g148_1_8', 'g148_1_9', 'g148_1_10', 'g148_1_11', 'g148_1_12', 'g148_2_1', 'g148_2_2', 'g148_2_3', 'g148_2_5', 'g148_2_6', 'g148_2_7', 'g148_2_8', 'g148_2_9', 'g148_2_10', 'g148_2_11', 'g148_2_12', 'g148_3', 'g148_4', 'g148_5_1', 'g148_5_2', 'g257', 'g153_1', 'g153_2', 'g258_1', 'g154_1', 'h155_1', 'h156_1', 'h252_1', 'h160_1', 'h160_2', 'h163_1', 'h163_2', 'h164', 'h165', 'h166', 'h269_1', 'h167_1_3', 'h167_2_3', 'h167_3_3', 'h167_4_3', 'h170_3', 'h271_1', 'h171_1', 'h172_1', 'h173_1', 'i174', 'i175', 'eg_ps2', 'MTO_CUOTA', 'MTO_EMER', 'MTO_HOGCON', 'MTO_DESAY', 'MTO_ALMUE', 'MTO_VACAS', 'MTO_OVEJA', 'MTO_CABALL', 'INDACELIAC', 'INDAEMER', 'PT1', 'PT2', 'PT4', 'HT13', 'YHOG', 'AFAM_H_DEC', 'AFAM_H', 'TUS_H_DEC', 'TUS_H', 'lp_06', 'li_06', 'lp_17', 'li_17', 'monto_imput_UTE', 'monto_imput_GAS', 'monto_imput_OSE', 'H_FONASA', 'montoGAS_RRAA', 'montoUTE_RRAA', 'montoOSE_RRAA', 'W_TRI', 'W_SEM', 'W_ANO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd7e259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicotmicas: 167\n",
      "Nominales: 73\n",
      "Ordinales: 24\n",
      "Nmericas discretas: 97\n",
      "Nmericas continuas: 115\n",
      "Total variables: 476\n"
     ]
    }
   ],
   "source": [
    "# ELIMINAMOS LAS VARIABLES QUE SE ELIMINARON EN LA LIMPIEZA DEL EDA SEGUN EL EXCEL GENERADO\n",
    "\n",
    "# Listado de variables a eliminar\n",
    "eliminar = [\n",
    "    'g141', 'anio', 'f80_2', 'f94_2', 'g141_1', 'g141_2', 'h163_2', 'f271', 'f278',\n",
    "    'f280_3', 'f81', 'f267', 'f294', 'f298', 'g_it_1', 'g_it_2', 'g149_1', 'e246',\n",
    "    'f277', 'f285', 'f101', 'f104', 'f110', 'f125', 'g256', 'REGION_4', 'f283',\n",
    "    'GR', 'd21_15_6', 'd229', 'd232', 'f307', 'g140_2', 'g140_3', 'HT19', 'g_id_1',\n",
    "    'g_id_2', 'g_id_3', 'g_id_2a', 'g_id_3a', 'g137_2', 'g139_1', 'MTO_EMER',\n",
    "    'MTO_DESAY', 'MTO_ALMUE', 'MTO_OVEJA', 'MTO_CABALL', 'PT4', 'AFAM_H', 'li_06', 'li_17'\n",
    "]\n",
    "\n",
    "# Eliminar variables de cada conjunto\n",
    "dicotomicas = [v for v in dicotomicas if v not in eliminar]\n",
    "nominales = [v for v in nominales if v not in eliminar]\n",
    "ordinales = [v for v in ordinales if v not in eliminar]\n",
    "numericas_discretas = [v for v in numericas_discretas if v not in eliminar]\n",
    "numericas_continuas = [v for v in numericas_continuas if v not in eliminar]\n",
    "\n",
    "# Imprimir tamaos para verificar\n",
    "print(f\"Dicotmicas: {len(dicotomicas)}\")\n",
    "print(f\"Nominales: {len(nominales)}\")\n",
    "print(f\"Ordinales: {len(ordinales)}\")\n",
    "print(f\"Nmericas discretas: {len(numericas_discretas)}\")\n",
    "print(f\"Nmericas continuas: {len(numericas_continuas)}\")\n",
    "print(\"Total variables:\", len(dicotomicas) + len(nominales) + len(ordinales) + len(numericas_discretas) + len(numericas_continuas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e978b5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55923, 476)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "609de9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICAMOS QUE NO ESTEN LAS VARIABLES ALTAMENTE CORRELACIONADAS\n",
    "for lista in [numericas_continuas, numericas_discretas, ordinales, nominales, dicotomicas]:\n",
    "    if 'HT11' in lista:\n",
    "        lista.remove('HT11')\n",
    "    if 'YDA' in lista:\n",
    "        lista.remove('YDA')\n",
    "    if 'YDA_SVL' in lista:\n",
    "        lista.remove('YDA_SVL')\n",
    "    if 'YSVL' in lista:\n",
    "        lista.remove('YSVL')\n",
    "    if 'log_YDA' in lista:\n",
    "        lista.remove('log_YDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d560921",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3a9d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTO LIBRERIAS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7640bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split UNA sola vez\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4c36275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines individuales con imputacin\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))  # No codifica, ya vienen como 0/1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7b2ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer final\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numericas_continuas),\n",
    "    ('ord', ordinal_transformer, ordinales),\n",
    "    ('nom', nominal_transformer, nominales),\n",
    "    ('bin', binary_transformer, dicotomicas),\n",
    "    ('disc', numeric_transformer, numericas_discretas)  # puede usar el mismo pipeline que numricas continuas\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c919a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut603933\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:241: UserWarning: Found unknown categories in columns [14, 28, 30, 32, 33, 34, 38, 39, 44, 54, 55, 65, 66] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes tras preprocesamiento:\n",
      "X_train_proc: (44738, 2740)\n",
      "X_test_proc : (11185, 2740)\n"
     ]
    }
   ],
   "source": [
    "# 4) Fit-transform SOLO con train y transform test\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Shapes tras preprocesamiento:\")\n",
    "print(\"X_train_proc:\", X_train_proc.shape)\n",
    "print(\"X_test_proc :\", X_test_proc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada15014",
   "metadata": {},
   "source": [
    "Dataset original (ech o X) con 55.923 filas, entonces con un test_size=0.2:\n",
    "- X_train y y_train  80% de los datos  44.738 filas\n",
    "- X_test y y_test  20% de los datos  11.185 filas\n",
    "\n",
    "Coincide con Shape del dataset procesado: (44738, 2889):\n",
    "- 44.738 filas para el conjunto de entrenamiento, 11.185 para el conjunto de test.\n",
    "- Las 2.740 columnas son el resultado del preprocesamiento, principalmente por el OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3398ce98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape inicial tras preprocesamiento: (44738, 2740)\n"
     ]
    }
   ],
   "source": [
    "# Convertir a DataFrame con nombres de columnas\n",
    "X_train_proc = pd.DataFrame(\n",
    "    X_train_proc,\n",
    "    columns=preprocessor.get_feature_names_out()\n",
    ")\n",
    "X_test_proc = pd.DataFrame(\n",
    "    X_test_proc,\n",
    "    columns=preprocessor.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(f\" Shape inicial tras preprocesamiento: {X_train_proc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cddcb9",
   "metadata": {},
   "source": [
    "## Verificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d80a760e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay NaN en X_train_proc? num__d8_2       False\n",
      "num__d8_3       False\n",
      "num__e584_1     False\n",
      "num__g_id_1a    False\n",
      "num__g126_1     False\n",
      "                ...  \n",
      "disc__h274_2    False\n",
      "disc__h274_3    False\n",
      "disc__h158_1    False\n",
      "disc__h158_2    False\n",
      "disc__h171_2    False\n",
      "Length: 2740, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"Hay NaN en X_train_proc?\", np.isnan(X_train_proc).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75d9aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Verificando X_train_proc:\n",
      "NaN: num__d8_2       0\n",
      "num__d8_3       0\n",
      "num__e584_1     0\n",
      "num__g_id_1a    0\n",
      "num__g126_1     0\n",
      "               ..\n",
      "disc__h274_2    0\n",
      "disc__h274_3    0\n",
      "disc__h158_1    0\n",
      "disc__h158_2    0\n",
      "disc__h171_2    0\n",
      "Length: 2740, dtype: int64\n",
      "Inf: num__d8_2       0\n",
      "num__d8_3       0\n",
      "num__e584_1     0\n",
      "num__g_id_1a    0\n",
      "num__g126_1     0\n",
      "               ..\n",
      "disc__h274_2    0\n",
      "disc__h274_3    0\n",
      "disc__h158_1    0\n",
      "disc__h158_2    0\n",
      "disc__h171_2    0\n",
      "Length: 2740, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut603933\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores demasiado grandes: num__d8_2       0\n",
      "num__d8_3       0\n",
      "num__e584_1     0\n",
      "num__g_id_1a    0\n",
      "num__g126_1     0\n",
      "               ..\n",
      "disc__h274_2    0\n",
      "disc__h274_3    0\n",
      "disc__h158_1    0\n",
      "disc__h158_2    0\n",
      "disc__h171_2    0\n",
      "Length: 2740, dtype: int64\n",
      " Verificando X_test_proc:\n",
      "NaN: num__d8_2       0\n",
      "num__d8_3       0\n",
      "num__e584_1     0\n",
      "num__g_id_1a    0\n",
      "num__g126_1     0\n",
      "               ..\n",
      "disc__h274_2    0\n",
      "disc__h274_3    0\n",
      "disc__h158_1    0\n",
      "disc__h158_2    0\n",
      "disc__h171_2    0\n",
      "Length: 2740, dtype: int64\n",
      "Inf: num__d8_2       0\n",
      "num__d8_3       0\n",
      "num__e584_1     0\n",
      "num__g_id_1a    0\n",
      "num__g126_1     0\n",
      "               ..\n",
      "disc__h274_2    0\n",
      "disc__h274_3    0\n",
      "disc__h158_1    0\n",
      "disc__h158_2    0\n",
      "disc__h171_2    0\n",
      "Length: 2740, dtype: int64\n",
      "Valores demasiado grandes: num__d8_2       0\n",
      "num__d8_3       0\n",
      "num__e584_1     0\n",
      "num__g_id_1a    0\n",
      "num__g126_1     0\n",
      "               ..\n",
      "disc__h274_2    0\n",
      "disc__h274_3    0\n",
      "disc__h158_1    0\n",
      "disc__h158_2    0\n",
      "disc__h171_2    0\n",
      "Length: 2740, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut603933\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "# Verificamos valores invalidos\n",
    "def verificar_valores_invalidos(X, nombre):\n",
    "    print(f\" Verificando {nombre}:\")\n",
    "    print(\"NaN:\", np.isnan(X).sum())\n",
    "    print(\"Inf:\", np.isinf(X).sum())\n",
    "    print(\"Valores demasiado grandes:\", np.sum(np.abs(X) > 1e10))\n",
    "\n",
    "verificar_valores_invalidos(X_train_proc, \"X_train_proc\")\n",
    "verificar_valores_invalidos(X_test_proc, \"X_test_proc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c611bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y_train\n",
      "NaN: 0\n",
      "Inf: 0\n",
      "Valores extremos: 0\n",
      "\n",
      " y_test\n",
      "NaN: 0\n",
      "Inf: 0\n",
      "Valores extremos: 0\n"
     ]
    }
   ],
   "source": [
    "print(\" y_train\")\n",
    "print(\"NaN:\", np.isnan(y_train).sum())\n",
    "print(\"Inf:\", np.isinf(y_train).sum())\n",
    "print(\"Valores extremos:\", np.sum(np.abs(y_train) > 1e10))\n",
    "\n",
    "print(\"\\n y_test\")\n",
    "print(\"NaN:\", np.isnan(y_test).sum())\n",
    "print(\"Inf:\", np.isinf(y_test).sum())\n",
    "print(\"Valores extremos:\", np.sum(np.abs(y_test) > 1e10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02c47f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train - min: 0.0 max: 14.75551820708067\n",
      "y_test - min: 0.0 max: 14.74570458948466\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train - min:\", np.min(y_train), \"max:\", np.max(y_train))\n",
    "print(\"y_test - min:\", np.min(y_test), \"max:\", np.max(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6debf5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas con varianza cero: 1\n"
     ]
    }
   ],
   "source": [
    "varianzas = np.var(X_train_proc, axis=0)\n",
    "print(\"Columnas con varianza cero:\", np.sum(varianzas == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a130faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas con varianza cero: ['num__g133_2']\n"
     ]
    }
   ],
   "source": [
    "varianzas = np.var(X_train_proc, axis=0)\n",
    "\n",
    "# ndices de columnas con varianza cero\n",
    "cols_cero_var = np.where(varianzas == 0)[0]\n",
    "\n",
    "# Nombres de las columnas\n",
    "nombres_cero_var = X_train_proc.columns[cols_cero_var]\n",
    "\n",
    "print(\"Columnas con varianza cero:\", list(nombres_cero_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7110505",
   "metadata": {},
   "source": [
    "La variable g133_2 es DERECHO A CULTIVO PARA CONSUMO PROPIO > Monto percibido por la venta de esos productos. No parece tener relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "976dcfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mximo absoluto en X_train_proc: 211.5112290163338\n"
     ]
    }
   ],
   "source": [
    "print(\"Valor mximo absoluto en X_train_proc:\", np.max(np.abs(X_train_proc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8881bb7",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2427de3c",
   "metadata": {},
   "source": [
    "## Comienza el notebook del modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb4e37",
   "metadata": {},
   "source": [
    "## Carga del dataset depurado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617142b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAMOS LIBRERIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea69066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes cargados:\n",
      "X: (55923, 2846)\n",
      "y: (55923,)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datasets limpios\n",
    "X = pd.read_csv(r'D:\\ut603933\\Tesis-MCD\\data_processed\\X_clean.csv')\n",
    "y = pd.read_csv(r'D:\\ut603933\\Tesis-MCD\\data_processed\\y_clean.csv').squeeze()  # .squeeze() para que sea Serie y no DataFrame\n",
    "\n",
    "print(\"Shapes cargados:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa6419",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b709e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes tras split:\n",
      "X_train: (44738, 2846)\n",
      "X_test: (11185, 2846)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shapes tras split:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93353bf",
   "metadata": {},
   "source": [
    "Definimos la funcion para evaluar los diferentes modelos con metricas en train y en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f664f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluar_modelo(modelo, X_train, y_train, X_test, y_test, nombre=\"modelo\"):\n",
    "    print(\" Entrenando modelo...\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    print(\" Generando predicciones...\")\n",
    "    y_pred_train = modelo.predict(X_train)\n",
    "    y_pred_test = modelo.predict(X_test)\n",
    "\n",
    "    print(\" Verificando predicciones...\")\n",
    "    print(f\"Mximo y_pred_test: {np.max(y_pred_test)}\")\n",
    "    print(f\"Mnimo y_pred_test: {np.min(y_pred_test)}\")\n",
    "\n",
    "    # ========= MTRICAS EN ESCALA LOG =========\n",
    "    print(\" Calculando mtricas en escala log...\")\n",
    "\n",
    "    # --- Train ---\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "    # --- Test ---\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "    # ========= MTRICAS EN ESCALA ORIGINAL (PESOS) =========\n",
    "    # Clip para evitar overflow al hacer exp()\n",
    "    y_train_clip = np.clip(y_train, 0, 30)\n",
    "    y_pred_train_clip = np.clip(y_pred_train, 0, 30)\n",
    "    y_test_clip = np.clip(y_test, 0, 30)\n",
    "    y_pred_test_clip = np.clip(y_pred_test, 0, 30)\n",
    "\n",
    "    y_train_original = np.exp(y_train_clip)\n",
    "    y_pred_train_original = np.exp(y_pred_train_clip)\n",
    "    y_test_original = np.exp(y_test_clip)\n",
    "    y_pred_test_original = np.exp(y_pred_test_clip)\n",
    "\n",
    "    print(f\"Mximo y_pred_original (clipped test): {np.max(y_pred_test_original)}\")\n",
    "\n",
    "    # --- Train pesos ---\n",
    "    mae_train_pesos = mean_absolute_error(y_train_original, y_pred_train_original)\n",
    "    rmse_train_pesos = np.sqrt(mean_squared_error(y_train_original, y_pred_train_original))\n",
    "\n",
    "    # --- Test pesos ---\n",
    "    mae_test_pesos = mean_absolute_error(y_test_original, y_pred_test_original)\n",
    "    rmse_test_pesos = np.sqrt(mean_squared_error(y_test_original, y_pred_test_original))\n",
    "\n",
    "    # ========= OUTPUT =========\n",
    "    print(\" Mtricas finales:\")\n",
    "    print(f\"Modelo: {nombre}\")\n",
    "\n",
    "    print(f\"[Train] R2: {r2_train:.4f} | MAE_log: {mae_train:.2f} | RMSE_log: {rmse_train:.2f}\")\n",
    "    print(f\"[Train] MAE_pesos: {mae_train_pesos:.2f} | RMSE_pesos: {rmse_train_pesos:.2f}\")\n",
    "\n",
    "    print(f\"[Test]  R2: {r2_test:.4f} | MAE_log: {mae_test:.2f} | RMSE_log: {rmse_test:.2f}\")\n",
    "    print(f\"[Test]  MAE_pesos: {mae_test_pesos:.2f} | RMSE_pesos: {rmse_test_pesos:.2f}\")\n",
    "\n",
    "    return {\n",
    "        \"modelo\": nombre,\n",
    "        \"R2_train\": r2_train,\n",
    "        \"MAE_log_train\": mae_train,\n",
    "        \"RMSE_log_train\": rmse_train,\n",
    "        \"MAE_pesos_train\": mae_train_pesos,\n",
    "        \"RMSE_pesos_train\": rmse_train_pesos,\n",
    "        \"R2_test\": r2_test,\n",
    "        \"MAE_log_test\": mae_test,\n",
    "        \"RMSE_log_test\": rmse_test,\n",
    "        \"MAE_pesos_test\": mae_test_pesos,\n",
    "        \"RMSE_pesos_test\": rmse_test_pesos\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8789d3",
   "metadata": {},
   "source": [
    "La funcion original daba error porque etabamos usando np.exp(y_pred_test) para volver a la escala original (en pesos), pero las predicciones incluyen valores extremadamente grandes. Eso explota al aplicar np.exp() y da como resultado inf, lo que rompe las mtricas como mean_squared_error. Entonces limitamos las predicciones antes de aplicar np.exp() con np.clip(). Esto evitar que np.exp() explote al exponenciar nmeros muy altos.\n",
    "\n",
    "Esta estrategia es valida cuando:\n",
    "- Ests evaluando predicciones en log-transformed regression.\n",
    "- El modelo produce algunos valores desproporcionados (outliers extremos).\n",
    "- El objetivo es evitar que un exp() distorsione totalmente las mtricas.\n",
    "\n",
    "Adems, ya tens tu variable objetivo (log_YDA) log-transformada, y no ests usando estos valores para reentrenamiento, sino para evaluacin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8cb45",
   "metadata": {},
   "source": [
    "## Modelo 1: Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee3e864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entrenando modelo...\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 498097080732.75256\n",
      "Mnimo y_pred_test: -241456690.6328601\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 10686474581524.463\n",
      " Mtricas finales:\n",
      "Modelo: Linear Regression\n",
      "[Train] R2: 0.8407 | MAE_log: 0.19 | RMSE_log: 0.27\n",
      "[Train] MAE_pesos: 24601.47 | RMSE_pesos: 412095.65\n",
      "[Test]  R2: -49619596753896103936.0000 | MAE_log: 44728901.45 | RMSE_log: 4709734138.24\n",
      "[Test]  MAE_pesos: 65924632661.27 | RMSE_pesos: 839345957414.24\n"
     ]
    }
   ],
   "source": [
    "# Regresin Lineal\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "resultados_modelos = []\n",
    "\n",
    "modelo_lr = LinearRegression()\n",
    "res_lr = evaluar_modelo(modelo_lr, X_train, y_train, X_test, y_test, nombre=\"Linear Regression\")\n",
    "\n",
    "# Verificacin defensiva antes de agregar\n",
    "if all(np.isfinite(v) for k, v in res_lr.items() if k != \"modelo\"):\n",
    "    resultados_modelos.append(res_lr)\n",
    "else:\n",
    "    print(\" Resultado no agregado por valores invlidos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc726f",
   "metadata": {},
   "source": [
    "Resultados:\n",
    " Entrenando modelo...\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 498097080732.75256\n",
    "Mnimo y_pred_test: -241456690.6328601\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 10686474581524.463\n",
    " Mtricas finales:\n",
    "Modelo: Linear Regression\n",
    "[Train] R2: 0.8407 | MAE_log: 0.19 | RMSE_log: 0.27\n",
    "[Train] MAE_pesos: 24601.47 | RMSE_pesos: 412095.65\n",
    "[Test]  R2: -49619596753896103936.0000 | MAE_log: 44728901.45 | RMSE_log: 4709734138.24\n",
    "[Test]  MAE_pesos: 65924632661.27 | RMSE_pesos: 839345957414.24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdceeb1",
   "metadata": {},
   "source": [
    " Observaciones:\n",
    "\n",
    "Train razonable, Test desastroso:\n",
    "- En train la regresin lineal da un R  0.84, lo cual parecera bueno.\n",
    "- Pero en test, el R se desploma a un valor negativo enorme ( 5e19 ), lo que significa que el modelo est prediciendo peor que una constante.\n",
    "\n",
    "Predicciones fuera de escala:\n",
    "- Los valores de y_pred_test tienen mnimos negativos y mximos descomunales (del orden de 10^11 en log y hasta 10^13 en pesos).\n",
    "- Esto indica inestabilidad numrica: la regresin lineal probablemente est afectada por multicolinealidad fuerte en tus features (variables altamente correlacionadas), lo que genera coeficientes enormes y extrapolaciones imposibles.\n",
    "\n",
    "Sobreajuste extremo:\n",
    "- La diferencia entre train y test es brutal: el modelo aprendi \"demasiado bien\" el train (ajustando a correlaciones espurias) pero no generaliza nada.\n",
    "\n",
    "Interpretacin prctica:\n",
    "- La regresin lineal no es adecuada para este problema con tantos features transformados.\n",
    "- Ya sabamos que tu dataset tiene alta dimensionalidad (muchas variables categricas one-hot, interacciones, etc.), y en ese contexto la regresin lineal sufre mucho.\n",
    "\n",
    " Conclusin:\n",
    "- Este modelo queda descartado como candidato serio.\n",
    "- Es til como baseline (comparacin mnima), pero los resultados en test lo invalidan.\n",
    "- La buena noticia es que confirma por qu Ridge, Random Forest, XGBoost y LightGBM son mucho ms prometedores: regulan, limitan complejidad y manejan no linealidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caff115",
   "metadata": {},
   "source": [
    "## Modelo 2: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2daa61db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entrenando modelo...\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 19.751230522344216\n",
      "Mnimo y_pred_test: 3.062307162842817\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 378312269.5048701\n",
      " Mtricas finales:\n",
      "Modelo: Ridge Regression\n",
      "[Train] R2: 0.8354 | MAE_log: 0.19 | RMSE_log: 0.28\n",
      "[Train] MAE_pesos: 25560.21 | RMSE_pesos: 470886.40\n",
      "[Test]  R2: 0.8133 | MAE_log: 0.20 | RMSE_log: 0.29\n",
      "[Test]  MAE_pesos: 57401.48 | RMSE_pesos: 3553744.19\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Entrenar y evaluar Ridge Regression\n",
    "# =========================================\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "modelo_ridge = Ridge(alpha=10, random_state=42)  # puedes probar alpha=1, 10, 100\n",
    "res_ridge = evaluar_modelo(modelo_ridge, X_train, y_train, X_test, y_test, nombre=\"Ridge Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eab8b9",
   "metadata": {},
   "source": [
    "Resultados:\n",
    " Entrenando modelo...\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 19.751230522344216\n",
    "Mnimo y_pred_test: 3.062307162842817\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 378312269.5048701\n",
    " Mtricas finales:\n",
    "Modelo: Ridge Regression\n",
    "[Train] R2: 0.8354 | MAE_log: 0.19 | RMSE_log: 0.28\n",
    "[Train] MAE_pesos: 25560.21 | RMSE_pesos: 470886.40\n",
    "[Test]  R2: 0.8133 | MAE_log: 0.20 | RMSE_log: 0.29\n",
    "[Test]  MAE_pesos: 57401.48 | RMSE_pesos: 3553744.19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202b214",
   "metadata": {},
   "source": [
    " Observaciones:\n",
    "\n",
    "Estabilidad respecto a Linear Regression:\n",
    "- A diferencia de la regresin lineal sin regularizacin (que explotaba en test), Ridge suaviza los coeficientes y da resultados mucho ms razonables.\n",
    "- No aparecen predicciones negativas absurdas ni valores fuera de escala extrema.\n",
    "\n",
    "Comparacin Train vs Test:\n",
    "- Train: R  0.835, mtricas log bastante ajustadas.\n",
    "- Test: R  0.813, apenas un poco peor que en train.\n",
    "- Esto indica que el modelo generaliza relativamente bien, sin overfitting grave.\n",
    "\n",
    "Mtricas en pesos:\n",
    "- El MAE en pesos es de  57 mil, lo cual ya es mucho ms razonable que lo que veamos con linear regression.\n",
    "- Pero ojo: el RMSE en pesos  3.5 millones es todava muy grande, lo que refleja que el modelo sufre con los outliers/extremos de ingreso.\n",
    "- Esto tiene sentido porque Ridge sigue siendo un modelo lineal  su capacidad para modelar no linealidades y colas largas es limitada.\n",
    "\n",
    "Interpretacin prctica:\n",
    "- Ridge es til como baseline regulado: mejora drsticamente a la regresin lineal simple y confirma que los features tienen capacidad predictiva.\n",
    "- Pero sigue siendo superado por modelos no lineales (RF, XGBoost, LightGBM), que manejan mejor la heterogeneidad del ingreso.\n",
    "\n",
    " Conclusin\n",
    "- Ridge ya es un modelo vlido (no se rompe como linear regression).\n",
    "- La diferencia entre train y test es aceptable, lo que muestra buena generalizacin.\n",
    "- Aun as, las mtricas en pesos muestran que probablemente no sea el mejor candidato final frente a modelos de ensamble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8225d",
   "metadata": {},
   "source": [
    "## Modelo 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42b03a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entrenando modelo...\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 13.997176447039841\n",
      "Mnimo y_pred_test: 3.0109590492056584\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 1199213.456621664\n",
      " Mtricas finales:\n",
      "Modelo: Random Forest\n",
      "[Train] R2: 0.9924 | MAE_log: 0.03 | RMSE_log: 0.06\n",
      "[Train] MAE_pesos: 4232.69 | RMSE_pesos: 13486.43\n",
      "[Test]  R2: 0.9399 | MAE_log: 0.09 | RMSE_log: 0.16\n",
      "[Test]  MAE_pesos: 11397.14 | RMSE_pesos: 33527.29\n"
     ]
    }
   ],
   "source": [
    "# 4) Modelo 2: Random Forest\n",
    "# (hiperparmetros base; ajustamos luego)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modelo_rf = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "res_rf = evaluar_modelo(modelo_rf, X_train, y_train, X_test, y_test, nombre=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e15e3",
   "metadata": {},
   "source": [
    "Resultados:\n",
    " Entrenando modelo...\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 13.997176447039841\n",
    "Mnimo y_pred_test: 3.0109590492056584\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 1199213.456621664\n",
    " Mtricas finales:\n",
    "Modelo: Random Forest\n",
    "[Train] R2: 0.9924 | MAE_log: 0.03 | RMSE_log: 0.06\n",
    "[Train] MAE_pesos: 4232.69 | RMSE_pesos: 13486.43\n",
    "[Test]  R2: 0.9399 | MAE_log: 0.09 | RMSE_log: 0.16\n",
    "[Test]  MAE_pesos: 11397.14 | RMSE_pesos: 33527.29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30138570",
   "metadata": {},
   "source": [
    " Observaciones:\n",
    "\n",
    "Rendimiento en Train:\n",
    "- R  0.9924, MAE y RMSE muy bajos  prcticamente perfecto sobre los datos de entrenamiento.\n",
    "- Esto es esperable porque los Random Forests, con muchos rboles profundos, tienden a \"memorizar\" el set de entrenamiento.\n",
    "\n",
    "Rendimiento en Test:\n",
    "- R  0.9399, todava muy alto.\n",
    "- MAE y RMSE en test siguen siendo bajos en comparacin con Ridge.\n",
    "- Esto indica que el modelo s generaliza muy bien, aunque no tanto como en train.\n",
    "\n",
    "Comparacin Train vs Test (clave para detectar sobreajuste):\n",
    "- Diferencia de R: 0.9924 (train)  0.9399 (test). Hay una cada, pero moderada y aceptable.\n",
    "- Errores: el error en test (MAE  11k, RMSE  33k) es mayor que en train (MAE  4k, RMSE  13k), pero no en forma escandalosa.\n",
    "- Esto nos dice que el modelo tiene cierto grado de sobreajuste natural (porque Random Forest memoriza), pero sigue siendo un modelo muy slido.\n",
    "\n",
    "Interpretacin prctica:\n",
    "- El modelo captura muy bien las relaciones complejas de las variables.\n",
    "- El sobreajuste est controlado gracias a la naturaleza del ensamble.\n",
    "- Si quisiramos an ms robustez podramos: Limitar profundidad (max_depth) o Usar menos estimadores (n_estimators). Pero probablemente perderamos algo de performance.\n",
    "\n",
    " Conclusin\n",
    "- S, hay una seal de sobreajuste porque el train es casi perfecto y el test cae, pero la cada es razonable.\n",
    "- En general, este Random Forest generaliza muy bien y supera claramente a los modelos lineales (Linear y Ridge).\n",
    "- Es un candidato fuerte al mejor modelo, aunque XGBoost/LightGBM suelen mejorar un poco ms la relacin bias-variance, es decir, logran casi la misma capacidad predictiva pero con menos sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293187bb",
   "metadata": {},
   "source": [
    "Eliminamos por ahora la auditoria de Feature importance.\n",
    "\n",
    "Eliminamos Randon Forest con Cross-Validation porque lo hacemos al final con los tres modelos. \n",
    "\n",
    "Tambien eliminamos los codigos de Cross-Validation de los otros modelo porque los hacemos todos juntos al final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58af56",
   "metadata": {},
   "source": [
    "## Modelo 4 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea92f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entrenando modelo...\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 14.268474578857422\n",
      "Mnimo y_pred_test: 3.6516520977020264\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 1572967.5\n",
      " Mtricas finales:\n",
      "Modelo: XGBoost\n",
      "[Train] R2: 0.9785 | MAE_log: 0.07 | RMSE_log: 0.10\n",
      "[Train] MAE_pesos: 7933.02 | RMSE_pesos: 13941.82\n",
      "[Test]  R2: 0.9352 | MAE_log: 0.12 | RMSE_log: 0.17\n",
      "[Test]  MAE_pesos: 13771.02 | RMSE_pesos: 32517.60\n"
     ]
    }
   ],
   "source": [
    "# 3) Entrenamos XGBoost\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "\n",
    "    modelo_xgb = XGBRegressor(\n",
    "        n_estimators=800,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",     # rpido y estable\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    res_xgb = evaluar_modelo(modelo_xgb, X_train, y_train, X_test, y_test, nombre=\"XGBoost\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\n[AVISO] xgboost no est instalado. Ejecuta: pip install xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9f48e",
   "metadata": {},
   "source": [
    "Resultados:\n",
    " Entrenando modelo...\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 14.268474578857422\n",
    "Mnimo y_pred_test: 3.6516520977020264\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 1572967.5\n",
    " Mtricas finales:\n",
    "Modelo: XGBoost\n",
    "[Train] R2: 0.9785 | MAE_log: 0.07 | RMSE_log: 0.10\n",
    "[Train] MAE_pesos: 7933.02 | RMSE_pesos: 13941.82\n",
    "[Test]  R2: 0.9352 | MAE_log: 0.12 | RMSE_log: 0.17\n",
    "[Test]  MAE_pesos: 13771.02 | RMSE_pesos: 32517.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6296ca",
   "metadata": {},
   "source": [
    " Observaciones:\n",
    "\n",
    "Rendimiento en Train:\n",
    "- R  0.9785, un poco menor que Random Forest (0.9924).\n",
    "- MAE y RMSE en train son bajos, pero no tan exageradamente buenos como RF.\n",
    "- Esto indica que XGBoost no memoriza tanto los datos como RF  ms regularizacin incorporada.\n",
    "\n",
    "Rendimiento en Test:\n",
    "- R  0.9352, muy cercano a Random Forest (0.9399).\n",
    "- Errores en pesos: MAE  13.7k y RMSE  32.5k, prcticamente iguales a RF (MAE  11.3k, RMSE  33.5k).\n",
    "\n",
    "Comparacin Train vs Test:\n",
    "- RF: R traintest cae de 0.9924  0.9399.\n",
    "- XGB: R traintest cae de 0.9785  0.9352.\n",
    "- La cada relativa es ms suave en XGB, lo que significa mejor control del sobreajuste.\n",
    "- En mtricas de error, XGB mantiene un equilibrio mejor: errores de train y test estn ms cercanos que en RF.\n",
    "\n",
    "Interpretacin prctica:\n",
    "- XGBoost mantiene un trade-off ms sano entre ajuste y generalizacin que RF.\n",
    "- Aunque RF logra un poquito mejor R en test, XGB se defiende con mayor robustez y menos gap.\n",
    "- Adems, XGB suele ser ms eficiente computacionalmente y escalable, lo que lo hace atractivo para datasets grandes.\n",
    "\n",
    " Conclusin:\n",
    "- Random Forest: mejor ajuste en train, un poco ms alto R en test, pero mayor seal de sobreajuste.\n",
    "- XGBoost: ligeramente menor R en test, pero con un gap traintest ms controlado  generaliza mejor.\n",
    "- Frente a los modelos lineales, ambos (RF y XGB) son muy superiores.\n",
    "- Si el objetivo es precisin mxima en este dataset, RF es apenas mejor.\n",
    "- Si el objetivo es modelo ms confiable y escalable, XGBoost tiene ventaja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a9076",
   "metadata": {},
   "source": [
    "## Modelo 5: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c663723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut603933\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entrenando modelo...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12042\n",
      "[LightGBM] [Info] Number of data points in the train set: 44738, number of used features: 1266\n",
      "[LightGBM] [Info] Start training from score 11.336580\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 14.222208468270537\n",
      "Mnimo y_pred_test: 3.436975694140844\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 1501850.3436166407\n",
      " Mtricas finales:\n",
      "Modelo: LightGBM\n",
      "[Train] R2: 0.9824 | MAE_log: 0.06 | RMSE_log: 0.09\n",
      "[Train] MAE_pesos: 7043.54 | RMSE_pesos: 13886.49\n",
      "[Test]  R2: 0.9370 | MAE_log: 0.11 | RMSE_log: 0.17\n",
      "[Test]  MAE_pesos: 13372.79 | RMSE_pesos: 31743.17\n"
     ]
    }
   ],
   "source": [
    "# 4) Entrenamos LightGBM\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "\n",
    "    modelo_lgb = LGBMRegressor(\n",
    "        n_estimators=1200,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=63,          # ~ 2^(max_depth) aprox (si max_depth ~ 6)\n",
    "        max_depth=-1,           # sin lmite (usa num_leaves como control)\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    res_lgb = evaluar_modelo(modelo_lgb, X_train, y_train, X_test, y_test, nombre=\"LightGBM\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\n[AVISO] lightgbm no est instalado. Ejecuta: pip install lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba8ca5",
   "metadata": {},
   "source": [
    "Resultados:\n",
    " Entrenando modelo...\n",
    "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056888 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 12042\n",
    "[LightGBM] [Info] Number of data points in the train set: 44738, number of used features: 1266\n",
    "[LightGBM] [Info] Start training from score 11.336580\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 14.222208468270537\n",
    "Mnimo y_pred_test: 3.436975694140844\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 1501850.3436166407\n",
    " Mtricas finales:\n",
    "Modelo: LightGBM\n",
    "[Train] R2: 0.9824 | MAE_log: 0.06 | RMSE_log: 0.09\n",
    "[Train] MAE_pesos: 7043.54 | RMSE_pesos: 13886.49\n",
    "[Test]  R2: 0.9370 | MAE_log: 0.11 | RMSE_log: 0.17\n",
    "[Test]  MAE_pesos: 13372.79 | RMSE_pesos: 31743.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2d60b",
   "metadata": {},
   "source": [
    " Observaciones\n",
    "\n",
    "Rendimiento en Train:\n",
    "- R  0.9824, en la misma liga que XGBoost (0.9785) y algo menor que RF (0.9924).\n",
    "- Errores en train: MAE  7.0k, RMSE  13.9k  comparables a XGBoost (7.9k / 13.9k).\n",
    "- Esto sugiere que, al igual que XGB, LightGBM evita memorizar en exceso (gap no tan extremo como RF).\n",
    "\n",
    "Rendimiento en Test:\n",
    "- R  0.9370, prcticamente igual a RF (0.9399) y XGB (0.9352).\n",
    "- Errores en pesos: MAE  13.3k y RMSE  31.7k  mejores que RF (11.3k / 33.5k) y muy parecidos a XGB (13.7k / 32.5k).\n",
    "- En RMSE_pesos, LightGBM es el ms bajo de los tres, lo que indica menos predicciones con errores grandes.\n",
    "\n",
    "Comparacin Train vs Test:\n",
    "- RF: cada de R muy grande (0.9924  0.9399), seal de sobreajuste.\n",
    "- XGB: cada ms moderada (0.9785  0.9352).\n",
    "- LGBM: cada parecida a XGB (0.9824  0.9370) pero con mejores mtricas de error en test.\n",
    "\n",
    "Interpretacin prctica:\n",
    "- LightGBM combina lo mejor de ambos mundos:\n",
    "- Ajusta casi tanto como RF en train.\n",
    "- Generaliza tan bien como XGB, incluso con un poquito menos error en test.\n",
    "- Adems, LightGBM suele ser ms rpido que XGB en datasets grandes y con muchas features (como el tuyo, con >1000).\n",
    "\n",
    " Conclusin:\n",
    "- Random Forest: mejor MAE en test  til si penalizamos errores absolutos medios.\n",
    "- XGBoost: ms balanceado que RF, menor sobreajuste, pero errores un poco ms altos.\n",
    "- LightGBM: el ms equilibrado  mantiene precisin alta y minimiza los errores grandes (mejor RMSE).\n",
    "- LightGBM es el mejor candidato final si buscamos un modelo robusto y eficiente. Si el criterio principal es MAE, RF puede ser apenas superior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d947c",
   "metadata": {},
   "source": [
    "Comparativo final (RF vs XGB vs LGBM):\n",
    "Modelo\t        R Train\tR Test\t    Gap Train-Test\tMAE Pesos (Test)\tRMSE Pesos (Test)\tComentario\n",
    "Random Forest\t0.9924\t    0.9399\t    0.0525\t        11.3k\t            33.5k\t            Ms preciso en MAE, pero con mayor sobreajuste.\n",
    "XGBoost\t        0.9785\t    0.9352\t    0.0433\t        13.7k\t            32.5k\t            Ms robusto que RF, gap ms controlado.\n",
    "LightGBM\t    0.9824\t    0.9370\t    0.0454\t        13.3k\t            31.7k\t            Balance ptimo: buen ajuste, generalizacin slida, menor RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b67c0f",
   "metadata": {},
   "source": [
    "Vemos los tipos de datos de train y test antes del Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3fac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tipos de datos en X_train ===\n",
      "float64    2846\n",
      "Name: count, dtype: int64\n",
      "num__d8_2       float64\n",
      "num__d8_3       float64\n",
      "num__e584_1     float64\n",
      "num__g_id_1     float64\n",
      "num__g_id_1a    float64\n",
      "num__g126_1     float64\n",
      "num__g126_2     float64\n",
      "num__g126_3     float64\n",
      "num__g126_4     float64\n",
      "num__g126_5     float64\n",
      "num__g126_6     float64\n",
      "num__g126_7     float64\n",
      "num__g126_8     float64\n",
      "num__g127_3     float64\n",
      "num__g128_1     float64\n",
      "num__g129_2     float64\n",
      "num__g130_1     float64\n",
      "num__g131_1     float64\n",
      "num__g133_1     float64\n",
      "num__g133_2     float64\n",
      "dtype: object\n",
      "\n",
      "=== Tipos de datos en X_test ===\n",
      "float64    2846\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Tipo de dato de y_train ===\n",
      "float64\n",
      "\n",
      "=== Tipo de dato de y_test ===\n",
      "float64\n",
      "\n",
      "Hay float64 en X_train?: 2846 columnas\n",
      "Hay float64 en X_test?: 2846 columnas\n"
     ]
    }
   ],
   "source": [
    "# Ver tipos de datos de los conjuntos luego del split\n",
    "print(\"=== Tipos de datos en X_train ===\")\n",
    "print(X_train.dtypes.value_counts())   # resumen\n",
    "print(X_train.dtypes.head(20))         # primeras 20 columnas\n",
    "\n",
    "print(\"\\n=== Tipos de datos en X_test ===\")\n",
    "print(X_test.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n=== Tipo de dato de y_train ===\")\n",
    "print(y_train.dtype)\n",
    "\n",
    "print(\"\\n=== Tipo de dato de y_test ===\")\n",
    "print(y_test.dtype)\n",
    "\n",
    "# Verificar si hay float64 y la cantidad exacta\n",
    "print(\"\\nHay float64 en X_train?:\", (X_train.dtypes == \"float64\").sum(), \"columnas\")\n",
    "print(\"Hay float64 en X_test?:\", (X_test.dtypes == \"float64\").sum(), \"columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681cd4d6",
   "metadata": {},
   "source": [
    "El siguiente chunk explota la memoria.\n",
    "\n",
    "Probamos con RandomizedSearchCV para RF, XGBoost y LightGBM con float32 y cv=3 y comparativo de modelos.\n",
    "\n",
    "Probamos por separado mas abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906991d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# =====================\n",
    "# 1) Convertir a float32 para reducir memoria\n",
    "# =====================\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test  = X_test.astype(np.float32)\n",
    "\n",
    "# =====================\n",
    "# 2) Funcin para evaluacin completa (train y test)\n",
    "# =====================\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluar_modelo(modelo, X_train, y_train, X_test, y_test, nombre=\"modelo\"):\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_train = modelo.predict(X_train)\n",
    "    y_pred_test = modelo.predict(X_test)\n",
    "\n",
    "    # --- Log scale ---\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "    # --- Original scale ---\n",
    "    y_train_clip = np.clip(y_train, 0, 30)\n",
    "    y_pred_train_clip = np.clip(y_pred_train, 0, 30)\n",
    "    y_test_clip = np.clip(y_test, 0, 30)\n",
    "    y_pred_test_clip = np.clip(y_pred_test, 0, 30)\n",
    "\n",
    "    y_train_original = np.exp(y_train_clip)\n",
    "    y_pred_train_original = np.exp(y_pred_train_clip)\n",
    "    y_test_original = np.exp(y_test_clip)\n",
    "    y_pred_test_original = np.exp(y_pred_test_clip)\n",
    "\n",
    "    mae_train_pesos = mean_absolute_error(y_train_original, y_pred_train_original)\n",
    "    rmse_train_pesos = np.sqrt(mean_squared_error(y_train_original, y_pred_train_original))\n",
    "\n",
    "    mae_test_pesos = mean_absolute_error(y_test_original, y_pred_test_original)\n",
    "    rmse_test_pesos = np.sqrt(mean_squared_error(y_test_original, y_pred_test_original))\n",
    "\n",
    "    return {\n",
    "        \"Modelo\": nombre,\n",
    "        \"R2_train\": r2_train, \"MAE_log_train\": mae_train, \"RMSE_log_train\": rmse_train,\n",
    "        \"MAE_pesos_train\": mae_train_pesos, \"RMSE_pesos_train\": rmse_train_pesos,\n",
    "        \"R2_test\": r2_test, \"MAE_log_test\": mae_test, \"RMSE_log_test\": rmse_test,\n",
    "        \"MAE_pesos_test\": mae_test_pesos, \"RMSE_pesos_test\": rmse_test_pesos\n",
    "    }\n",
    "\n",
    "# =====================\n",
    "# 3) RandomizedSearchCV para cada modelo\n",
    "# =====================\n",
    "\n",
    "# --- Random Forest ---\n",
    "param_rf = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [10, 15, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "search_rf = RandomizedSearchCV(rf, param_rf, n_iter=10, cv=3, scoring='r2',\n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "t0 = time.time()\n",
    "search_rf.fit(X_train, y_train)\n",
    "print(\"Random Forest mejores params:\", search_rf.best_params_, \"Tiempo:\", round(time.time()-t0, 2), \"s\")\n",
    "\n",
    "# --- XGBoost ---\n",
    "param_xgb = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "search_xgb = RandomizedSearchCV(xgb, param_xgb, n_iter=10, cv=3, scoring='r2',\n",
    "                                verbose=2, random_state=42, n_jobs=-1)\n",
    "t0 = time.time()\n",
    "search_xgb.fit(X_train, y_train)\n",
    "print(\"XGBoost mejores params:\", search_xgb.best_params_, \"Tiempo:\", round(time.time()-t0, 2), \"s\")\n",
    "\n",
    "# --- LightGBM ---\n",
    "param_lgb = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [-1, 10, 15, 20],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "lgb = LGBMRegressor(objective='regression', random_state=42, n_jobs=-1)\n",
    "search_lgb = RandomizedSearchCV(lgb, param_lgb, n_iter=10, cv=3, scoring='r2',\n",
    "                                verbose=2, random_state=42, n_jobs=-1)\n",
    "t0 = time.time()\n",
    "search_lgb.fit(X_train, y_train)\n",
    "print(\"LightGBM mejores params:\", search_lgb.best_params_, \"Tiempo:\", round(time.time()-t0, 2), \"s\")\n",
    "\n",
    "# =====================\n",
    "# 4) Evaluar y comparar (con train vs test)\n",
    "# =====================\n",
    "resultados = []\n",
    "resultados.append(evaluar_modelo(search_rf.best_estimator_, X_train, y_train, X_test, y_test, \"Random Forest\"))\n",
    "resultados.append(evaluar_modelo(search_xgb.best_estimator_, X_train, y_train, X_test, y_test, \"XGBoost\"))\n",
    "resultados.append(evaluar_modelo(search_lgb.best_estimator_, X_train, y_train, X_test, y_test, \"LightGBM\"))\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(\"\\n Comparativa de modelos (Train vs Test):\")\n",
    "print(df_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9bd62",
   "metadata": {},
   "source": [
    "El codigo anterior satura la RAM. Los hacemos por separado y luego comparamos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a56b7",
   "metadata": {},
   "source": [
    "## Modelo 6: Random Forest con RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8502f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      " Random Forest mejores params: {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': None} Tiempo: 15494.18 s\n",
      " Entrenando modelo...\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 13.951850895584109\n",
      "Mnimo y_pred_test: 2.885444387850904\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 1146071.8786031357\n",
      " Mtricas finales:\n",
      "Modelo: Random Forest\n",
      "[Train] R2: 0.9882 | MAE_log: 0.04 | RMSE_log: 0.07\n",
      "[Train] MAE_pesos: 5031.06 | RMSE_pesos: 17581.47\n",
      "[Test]  R2: 0.9367 | MAE_log: 0.10 | RMSE_log: 0.17\n",
      "[Test]  MAE_pesos: 11813.12 | RMSE_pesos: 34596.79\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Random Forest - RandomizedSearchCV\n",
    "# ========================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "\n",
    "param_rf = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [10, 15, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "search_rf = RandomizedSearchCV(rf, param_rf, n_iter=10, cv=3, scoring='r2',\n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "t0 = time.time()\n",
    "search_rf.fit(X_train.astype(\"float32\"), y_train)\n",
    "print(\" Random Forest mejores params:\", search_rf.best_params_, \"Tiempo:\", round(time.time()-t0, 2), \"s\")\n",
    "\n",
    "res_rf = evaluar_modelo(search_rf.best_estimator_,\n",
    "                        X_train.astype(\"float32\"), y_train,\n",
    "                        X_test.astype(\"float32\"), y_test,\n",
    "                        nombre=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c974b6f",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
    " Random Forest mejores params: {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': None} Tiempo: 15494.18 s\n",
    " Entrenando modelo...\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 13.951850895584109\n",
    "Mnimo y_pred_test: 2.885444387850904\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 1146071.8786031357\n",
    " Mtricas finales:\n",
    "Modelo: Random Forest\n",
    "[Train] R2: 0.9882 | MAE_log: 0.04 | RMSE_log: 0.07\n",
    "[Train] MAE_pesos: 5031.06 | RMSE_pesos: 17581.47\n",
    "[Test]  R2: 0.9367 | MAE_log: 0.10 | RMSE_log: 0.17\n",
    "[Test]  MAE_pesos: 11813.12 | RMSE_pesos: 34596.79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cb674",
   "metadata": {},
   "source": [
    " Observaciones:\n",
    "\n",
    "Parmetros ptimos encontrados:\n",
    "- n_estimators=600, min_samples_split=5, min_samples_leaf=2, max_depth=None.\n",
    "- En comparacin con los valores por defecto, estos parmetros buscan mayor profundidad y estabilidad en los splits  permiten ms flexibilidad al bosque, pero con restricciones en min_samples_split y min_samples_leaf para evitar splits demasiado pequeos (reduce sobreajuste).\n",
    "\n",
    "Tiempo de cmputo:\n",
    "~ 4.3 horas (15494 s).\n",
    "- Bastante costoso en tiempo, lo cual es esperable dado el tamao del dataset (44k train, 1.2k features, 600 rboles).\n",
    "\n",
    "Resultados en Train:\n",
    "- R = 0.9882  excelente ajuste, aunque un poco menos que el RF sin tuning (0.9924).\n",
    "- MAE_pesos  5.0k y RMSE_pesos  17.6k  valores ms bajos que antes (el RF sin tuning tena 4.2k / 13.4k).\n",
    "- En resumen: ligera prdida en R, pero mejora en estabilidad de errores.\n",
    "\n",
    "Resultados en Test:\n",
    "- R = 0.9367, casi igual al RF sin tuning (0.9399).\n",
    "- MAE_pesos  11.8k, RMSE_pesos  34.6k  muy parecidos al modelo sin tuning (11.3k / 33.5k).\n",
    "- No hay mejora clara en generalizacin; los resultados en test se mantienen en el mismo nivel.\n",
    "\n",
    " Conclusin:\n",
    "- El cross validation mejor la robustez del modelo en train (los errores no son tan bajos como antes  menor sobreajuste).\n",
    "- En test, los resultados no mejoraron significativamente respecto al modelo default, lo que sugiere que RF ya estaba bastante bien configurado.\n",
    "- RF sigue mostrando un gap relativamente grande entre train y test  indicio de cierto sobreajuste residual.\n",
    "- En pocas palabras:\n",
    "    - S hubo regularizacin gracias al tuning.\n",
    "    - No hubo un salto de calidad en test  es probable que XGBoost o LightGBM sigan siendo ms competitivos en generalizacin y eficiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6e44f",
   "metadata": {},
   "source": [
    " Comparacin antes vs despus del CV\n",
    "Modelo\t        R Train\tR Test\tMAE_pesos Train\tRMSE_pesos Train\tMAE_pesos Test\tRMSE_pesos Test\n",
    "RF sin tuning\t0.9924\t    0.9399\t4.2k\t        13.5k\t            11.3k\t        33.5k\n",
    "RF con CV\t    0.9882\t    0.9367\t5.0k\t        17.6k\t            11.8k\t        34.6k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0dde1",
   "metadata": {},
   "source": [
    "## Modelo 7: XGBoost con RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd039157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      " XGBoost mejores params: {'subsample': 0.8, 'n_estimators': 600, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.8} Tiempo: 418.93 s\n",
      " Entrenando modelo...\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 14.895726203918457\n",
      "Mnimo y_pred_test: 2.91107439994812\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 2945314.75\n",
      " Mtricas finales:\n",
      "Modelo: XGBoost\n",
      "[Train] R2: 0.9511 | MAE_log: 0.11 | RMSE_log: 0.15\n",
      "[Train] MAE_pesos: 12755.46 | RMSE_pesos: 22632.87\n",
      "[Test]  R2: 0.9154 | MAE_log: 0.14 | RMSE_log: 0.19\n",
      "[Test]  MAE_pesos: 16259.64 | RMSE_pesos: 36975.82\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# XGBoost - RandomizedSearchCV\n",
    "# ========================================\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "param_xgb = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1, tree_method=\"hist\")\n",
    "search_xgb = RandomizedSearchCV(xgb, param_xgb, n_iter=10, cv=3, scoring='r2',\n",
    "                                verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "t0 = time.time()\n",
    "search_xgb.fit(X_train.astype(\"float32\"), y_train)\n",
    "print(\" XGBoost mejores params:\", search_xgb.best_params_, \"Tiempo:\", round(time.time()-t0, 2), \"s\")\n",
    "\n",
    "res_xgb = evaluar_modelo(search_xgb.best_estimator_,\n",
    "                         X_train.astype(\"float32\"), y_train,\n",
    "                         X_test.astype(\"float32\"), y_test,\n",
    "                         nombre=\"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258dc0f",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
    " XGBoost mejores params: {'subsample': 0.8, 'n_estimators': 600, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.8} Tiempo: 418.93 s\n",
    " Entrenando modelo...\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 14.895726203918457\n",
    "Mnimo y_pred_test: 2.91107439994812\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 2945314.75\n",
    " Mtricas finales:\n",
    "Modelo: XGBoost\n",
    "[Train] R2: 0.9511 | MAE_log: 0.11 | RMSE_log: 0.15\n",
    "[Train] MAE_pesos: 12755.46 | RMSE_pesos: 22632.87\n",
    "[Test]  R2: 0.9154 | MAE_log: 0.14 | RMSE_log: 0.19\n",
    "[Test]  MAE_pesos: 16259.64 | RMSE_pesos: 36975.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c08cc7",
   "metadata": {},
   "source": [
    " Observaciones:\n",
    "\n",
    "Parmetros ptimos encontrados:\n",
    "- n_estimators=600, max_depth=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8.\n",
    "- Esto refleja un modelo ms regularizado:\n",
    "    - max_depth=5 limita la complejidad de cada rbol (evita sobreajuste).\n",
    "    - subsample y colsample_bytree < 1 introducen aleatoriedad  mayor generalizacin.\n",
    "\n",
    "Tiempo de cmputo:\n",
    "~ 419 segundos (7 minutos).\n",
    "- Mucho ms eficiente que Random Forest (que tard ~4.3 horas). Esto confirma que XGBoost es ms escalable y rpido.\n",
    "\n",
    "Resultados en Train:\n",
    "- R = 0.9511, bastante ms bajo que la versin sin tuning (0.9785).\n",
    "- MAE_pesos  12.8k y RMSE_pesos  22.6k  los errores en train aumentan, lo cual es esperado: el modelo sacrifica ajuste en train para evitar sobreajuste.\n",
    "\n",
    "Resultados en Test:\n",
    "- R = 0.9154, algo menor que antes (0.9352).\n",
    "- MAE_pesos  16.3k, RMSE_pesos  37.0k  tambin aumentan en comparacin al modelo sin tuning.\n",
    "- El modelo es ms conservador, pero no logra mejorar en generalizacin.\n",
    "\n",
    " Conclusin:\n",
    "- El tuning redujo el sobreajuste (menor diferencia traintest), pero a costa de peor rendimiento absoluto en test.\n",
    "- Mientras que el RF gan en robustez con CV sin perder mucho en test, en XGBoost el tuning lo penaliz ms de lo necesario.\n",
    "- Esto puede deberse a que el espacio de bsqueda fue relativamente conservador (pocas combinaciones), o a que el modelo ya estaba en un punto casi ptimo en su configuracin base.\n",
    "- En resumen:\n",
    "    - XGBoost sin tuning fue mejor en este caso.\n",
    "    - XGBoost con CV es ms regularizado, menos propenso a sobreajustar, pero no logra un mejor score en test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b3cf0",
   "metadata": {},
   "source": [
    " Comparacin antes vs despus del CV\n",
    "Modelo\t        R Train\tR Test\tMAE_pesos Train\tRMSE_pesos Train\tMAE_pesos Test\tRMSE_pesos Test\n",
    "XGB sin tuning\t0.9785\t    0.9352\t7.9k\t        13.9k\t            13.8k\t        32.5k\n",
    "XGB con CV\t    0.9511\t    0.9154\t12.8k\t        22.6k\t            16.3k       \t37.0k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1669c",
   "metadata": {},
   "source": [
    "## Modelo 8: LightGBM con RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c303ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut603933\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12036\n",
      "[LightGBM] [Info] Number of data points in the train set: 44738, number of used features: 1266\n",
      "[LightGBM] [Info] Start training from score 11.336580\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      " LightGBM mejores params: {'subsample': 0.8, 'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.8} Tiempo: 126.4 s\n",
      " Entrenando modelo...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12036\n",
      "[LightGBM] [Info] Number of data points in the train set: 44738, number of used features: 1266\n",
      "[LightGBM] [Info] Start training from score 11.336580\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      " Generando predicciones...\n",
      " Verificando predicciones...\n",
      "Mximo y_pred_test: 14.333617997151576\n",
      "Mnimo y_pred_test: 2.8322984329855077\n",
      " Calculando mtricas en escala log...\n",
      "Mximo y_pred_original (clipped test): 1678847.3205156547\n",
      " Mtricas finales:\n",
      "Modelo: LightGBM\n",
      "[Train] R2: 0.9622 | MAE_log: 0.10 | RMSE_log: 0.13\n",
      "[Train] MAE_pesos: 10885.25 | RMSE_pesos: 20842.45\n",
      "[Test]  R2: 0.9237 | MAE_log: 0.13 | RMSE_log: 0.18\n",
      "[Test]  MAE_pesos: 15118.20 | RMSE_pesos: 34234.01\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# LightGBM - RandomizedSearchCV\n",
    "# ========================================\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "param_lgb = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [-1, 10, 15, 20],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "lgb = LGBMRegressor(objective='regression', random_state=42, n_jobs=-1)\n",
    "search_lgb = RandomizedSearchCV(lgb, param_lgb, n_iter=10, cv=3, scoring='r2',\n",
    "                                verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "t0 = time.time()\n",
    "search_lgb.fit(X_train.astype(\"float32\"), y_train)\n",
    "print(\" LightGBM mejores params:\", search_lgb.best_params_, \"Tiempo:\", round(time.time()-t0, 2), \"s\")\n",
    "\n",
    "res_lgb = evaluar_modelo(search_lgb.best_estimator_,\n",
    "                         X_train.astype(\"float32\"), y_train,\n",
    "                         X_test.astype(\"float32\"), y_test,\n",
    "                         nombre=\"LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb7b42",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
    "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059263 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 12036\n",
    "[LightGBM] [Info] Number of data points in the train set: 44738, number of used features: 1266\n",
    "[LightGBM] [Info] Start training from score 11.336580\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    " LightGBM mejores params: {'subsample': 0.8, 'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.8} Tiempo: 126.4 s\n",
    " Entrenando modelo...\n",
    "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074892 seconds.\n",
    "You can set `force_col_wise=true` to remove the overhead.\n",
    "[LightGBM] [Info] Total Bins 12036\n",
    "[LightGBM] [Info] Number of data points in the train set: 44738, number of used features: 1266\n",
    "[LightGBM] [Info] Start training from score 11.336580\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
    " Generando predicciones...\n",
    " Verificando predicciones...\n",
    "Mximo y_pred_test: 14.333617997151576\n",
    "Mnimo y_pred_test: 2.8322984329855077\n",
    " Calculando mtricas en escala log...\n",
    "Mximo y_pred_original (clipped test): 1678847.3205156547\n",
    " Mtricas finales:\n",
    "Modelo: LightGBM\n",
    "[Train] R2: 0.9622 | MAE_log: 0.10 | RMSE_log: 0.13\n",
    "[Train] MAE_pesos: 10885.25 | RMSE_pesos: 20842.45\n",
    "[Test]  R2: 0.9237 | MAE_log: 0.13 | RMSE_log: 0.18\n",
    "[Test]  MAE_pesos: 15118.20 | RMSE_pesos: 34234.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9802d614",
   "metadata": {},
   "source": [
    " Observaciones:\n",
    "\n",
    "Parmetros ptimos:\n",
    "- n_estimators=600, max_depth=10, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8.\n",
    "- Similar a XGBoost: profundidad limitada, muestreo parcial y tasa de aprendizaje estndar (0.1).\n",
    "- Esto apunta a un modelo ms balanceado entre bias y varianza.\n",
    "\n",
    "Tiempo de cmputo:\n",
    "~ 126 segundos (2 minutos).\n",
    "- Mucho ms rpido que XGBoost (419s) y que Random Forest (ms de 4 horas).\n",
    "- Confirma que LightGBM es el ms eficiente en tiempo y escalabilidad.\n",
    "\n",
    "Resultados en Train:\n",
    "- R = 0.9622, menor que la versin sin tuning (0.9824).\n",
    "- MAE_pesos  10.9k, RMSE_pesos  20.8k  errores ms altos que antes.\n",
    "- El modelo se regulariza ms y pierde algo de ajuste en train.\n",
    "\n",
    "Resultados en Test:\n",
    "- R = 0.9237, menor que el 0.9370 previo.\n",
    "- MAE_pesos  15.1k, RMSE_pesos  34.2k  tambin peores que en la versin base.\n",
    "- Aunque generaliza decentemente, la ganancia respecto al baseline es negativa.\n",
    "\n",
    " Conclusin:\n",
    "- El tuning redujo el sobreajuste: la brecha entre train y test se achic.\n",
    "- Sin embargo, empeoraron las mtricas absolutas en test: perdi precisin al generalizar.\n",
    "- En este caso, igual que con XGBoost, la configuracin por defecto ya estaba bastante afinada y el RandomizedSearch termin sobre-regularizando.\n",
    "- LightGBM sigue siendo atractivo por su rapidez y eficiencia, pero en trminos de performance, su versin sin tuning fue ms competitiva.\n",
    "\n",
    " En suma:\n",
    "- Usar los modelos base de XGBoost y LightGBM (sin tuning) como benchmarks principales.\n",
    "- El tuning puede ser reintentado con un espacio de bsqueda ms amplio (ej. learning_rate < 0.05, n_estimators mayores, min_child_samples, reg_alpha, reg_lambda), pero en este setup concreto no aport mejora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9edef1",
   "metadata": {},
   "source": [
    " Comparacin antes vs despus del CV\n",
    "Modelo\t        R Train\tR Test\tMAE_pesos Train\tRMSE_pesos Train\tMAE_pesos Test\tRMSE_pesos Test\n",
    "LGBM sin tuning\t0.9824\t    0.9370\t7.0k\t        13.9k\t            13.4k\t        31.7k\n",
    "LGBM con CV\t    0.9622\t    0.9237\t10.9k\t        20.8k\t            15.1k\t        34.2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3528ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Comparativa de modelos:\n",
      "          modelo  R2_train  MAE_log_train  RMSE_log_train  MAE_pesos_train  \\\n",
      "0  Random Forest  0.988210       0.039193        0.074590      5031.060495   \n",
      "1        XGBoost  0.951129       0.114570        0.151859     12755.464407   \n",
      "2       LightGBM  0.962241       0.097624        0.133482     10885.251028   \n",
      "\n",
      "   RMSE_pesos_train   R2_test  MAE_log_test  RMSE_log_test  MAE_pesos_test  \\\n",
      "0      17581.469757  0.936717      0.095320       0.168195    11813.118758   \n",
      "1      22632.868165  0.915410      0.138801       0.194459    16259.640911   \n",
      "2      20842.450304  0.923734      0.129267       0.184644    15118.198688   \n",
      "\n",
      "   RMSE_pesos_test  \n",
      "0     34596.788107  \n",
      "1     36975.824651  \n",
      "2     34234.012859  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_log_train</th>\n",
       "      <th>RMSE_log_train</th>\n",
       "      <th>MAE_pesos_train</th>\n",
       "      <th>RMSE_pesos_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_log_test</th>\n",
       "      <th>RMSE_log_test</th>\n",
       "      <th>MAE_pesos_test</th>\n",
       "      <th>RMSE_pesos_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.988210</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>0.074590</td>\n",
       "      <td>5031.060495</td>\n",
       "      <td>17581.469757</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>0.095320</td>\n",
       "      <td>0.168195</td>\n",
       "      <td>11813.118758</td>\n",
       "      <td>34596.788107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.962241</td>\n",
       "      <td>0.097624</td>\n",
       "      <td>0.133482</td>\n",
       "      <td>10885.251028</td>\n",
       "      <td>20842.450304</td>\n",
       "      <td>0.923734</td>\n",
       "      <td>0.129267</td>\n",
       "      <td>0.184644</td>\n",
       "      <td>15118.198688</td>\n",
       "      <td>34234.012859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.951129</td>\n",
       "      <td>0.114570</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>12755.464407</td>\n",
       "      <td>22632.868165</td>\n",
       "      <td>0.915410</td>\n",
       "      <td>0.138801</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>16259.640911</td>\n",
       "      <td>36975.824651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          modelo  R2_train  MAE_log_train  RMSE_log_train  MAE_pesos_train  \\\n",
       "0  Random Forest  0.988210       0.039193        0.074590      5031.060495   \n",
       "1       LightGBM  0.962241       0.097624        0.133482     10885.251028   \n",
       "2        XGBoost  0.951129       0.114570        0.151859     12755.464407   \n",
       "\n",
       "   RMSE_pesos_train   R2_test  MAE_log_test  RMSE_log_test  MAE_pesos_test  \\\n",
       "0      17581.469757  0.936717      0.095320       0.168195    11813.118758   \n",
       "1      20842.450304  0.923734      0.129267       0.184644    15118.198688   \n",
       "2      22632.868165  0.915410      0.138801       0.194459    16259.640911   \n",
       "\n",
       "   RMSE_pesos_test  \n",
       "0     34596.788107  \n",
       "1     34234.012859  \n",
       "2     36975.824651  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# Resumen comparativo de modelos\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Crear lista con los resultados de los que efectivamente corriste\n",
    "resultados = []\n",
    "if 'res_rf' in locals():\n",
    "    resultados.append(res_rf)\n",
    "if 'res_xgb' in locals():\n",
    "    resultados.append(res_xgb)\n",
    "if 'res_lgb' in locals():\n",
    "    resultados.append(res_lgb)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"\\n Comparativa de modelos:\")\n",
    "print(df_resultados)\n",
    "\n",
    "# Opcional: ordenar por R test descendente\n",
    "df_resultados = df_resultados.sort_values(by=\"R2_test\", ascending=False)\n",
    "df_resultados.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23864bc1",
   "metadata": {},
   "source": [
    "Modelo\t        Versin\tTiempo (s)\tR Train\tR Test\tMAE_pesos Train\tRMSE_pesos Train\tMAE_pesos Test\tRMSE_pesos Test\n",
    "Random Forest\tBase\t~300\t    0.9924\t    0.9399\t4.2k\t        13.5k\t            11.4k\t        33.5k\n",
    "Random Forest\tCV\t    15,494\t    0.9882\t    0.9367\t5.0k\t        17.6k\t            11.8k\t        34.6k\n",
    "XGBoost\t        Base\t63\t        0.9785\t    0.9352\t7.9k\t        13.9k\t            13.8k\t        32.5k\n",
    "XGBoost     \tCV\t    419\t        0.9511\t    0.9154\t12.8k\t        22.6k\t            16.3k\t        37.0k\n",
    "LightGBM\t    Base\t30\t        0.9824\t    0.9370\t7.0k\t        13.9k\t            13.4k\t        31.7k\n",
    "LightGBM\t    CV\t    126\t        0.9622\t    0.9237\t10.9k\t        20.8k\t            15.1k\t        34.2k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f042a4b",
   "metadata": {},
   "source": [
    " Anlisis comparativo:\n",
    "\n",
    "Random Forest:\n",
    "- Mejor R en train (0.9924), pero con claro riesgo de sobreajuste.\n",
    "- Generaliza bien en test (R=0.94, MAE11.4k).\n",
    "- El CV empeora resultados y adems es carsimo en tiempo (ms de 4 horas).\n",
    "\n",
    "XGBoost:\n",
    "- Muy buen balance base (R=0.9352, MAE13.8k).\n",
    "- Mucho ms eficiente en tiempo (63s) que RF.\n",
    "- CV lo sobre-regulariz, bajando a R=0.9154  empeora mtricas.\n",
    "\n",
    "LightGBM:\n",
    "- El ms rpido (30s base).\n",
    "- R=0.9370, MAE13.4k  mejor test absoluto.\n",
    "- CV tambin lo sobre-regulariz  pierde precisin.\n",
    "\n",
    " Conclusin Final:\n",
    "- Ganador absoluto en balance performance/tiempo: LightGBM (versin base):\n",
    "    - Mejor MAE y RMSE en test.\n",
    "    - Ms rpido que RF y XGB.\n",
    "    - Generalizacin muy buena sin sobreajuste extremo.\n",
    "- Alternativa slida: XGBoost (versin base):\n",
    "    - Muy competitivo, solo un poco peor que LightGBM en mtricas.\n",
    "    - Algo ms lento, pero ms estable.\n",
    "- Random Forest: Buen desempeo, pero demasiado costoso en tiempo y con ms riesgo de sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af7756",
   "metadata": {},
   "source": [
    "## Curva de validacin / Curva de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbe0aa",
   "metadata": {},
   "source": [
    "XGBoost con curva de validacin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fe93cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir modelo con muchos rboles\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000,  # nmero alto para observar la curva\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=50  \n",
    ")\n",
    "\n",
    "# Entrenar con conjunto de validacin\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "\n",
    "# Extraer resultados\n",
    "results = xgb.evals_result()\n",
    "\n",
    "# Graficar curva de aprendizaje\n",
    "epochs = len(results['validation_0']['rmse'])\n",
    "x_axis = range(0, epochs)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x_axis, results['validation_0']['rmse'], label='Train')\n",
    "plt.plot(x_axis, results['validation_1']['rmse'], label='Test')\n",
    "plt.xlabel('Nmero de rboles')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Curva de aprendizaje XGBoost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e129b8",
   "metadata": {},
   "source": [
    "Forma general:\n",
    "- Tanto el RMSE de Train como el de Test comienzan alrededor de 0.7 y caen rpidamente a medida que se agregan rboles.\n",
    "- Despus de unas ~100 iteraciones, la cada se suaviza y ambas curvas se aplanan.\n",
    "- La curva de Train sigue bajando lentamente, mientras que la de Test se estabiliza en torno a 0.20.\n",
    "\n",
    "Sobreajuste (overfitting):\n",
    "- La separacin entre las curvas es un buen indicador de sobreajuste.\n",
    "- En este caso, el gap TrainTest es pequeo pero creciente:\n",
    "- A partir de ~200 rboles ya se nota que Train sigue mejorando mientras Test se estanca.\n",
    "- Esto indica un inicio de overfitting, aunque no es extremo porque la curva de Test no vuelve a subir.\n",
    "\n",
    "Punto ptimo:\n",
    "- El modelo alcanza una meseta en Test cerca de los 200300 rboles.\n",
    "- Entrenar hasta 1000 rboles no aporta mejoras sustanciales en Test (solo baja en Train).\n",
    "- Esto sugiere que el nmero ptimo de rboles debera estar alrededor de 200300, ms all de eso no vale la pena.\n",
    "\n",
    "Interpretacin prctica:\n",
    "- El modelo generaliza bien: no hay un salto brusco de Test hacia arriba (que sera sobreajuste fuerte).\n",
    "- Se podra:\n",
    "    - Reducir n_estimators (o usar early stopping) en torno a 200300.\n",
    "    - Explorar ajustar otros hiperparmetros (max_depth, eta, subsample, colsample_bytree) para reducir an ms la brecha TrainTest.\n",
    "    - Si el objetivo es mejorar Test, aumentar regularizacin (reg_alpha, reg_lambda) puede ayudar.\n",
    "\n",
    "Conclusion:\n",
    "- Nuestro XGBoost funciona bien con 800 es perfectamente lgico porque tenemos un learning_rate bajo de 0.05.\n",
    "- Lo importante es no entrenar innecesariamente de ms: con early stopping puedes dejar que el modelo decida cundo parar (aunque hayas puesto n_estimators=1000, por ejemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791cd33",
   "metadata": {},
   "source": [
    "LightGBM con curva de validacin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6738edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=10) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=1024) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=10) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=1024) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12042\n",
      "[LightGBM] [Info] Number of data points in the train set: 44738, number of used features: 1266\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=10) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=1024) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Start training from score 11.336580\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tTrain's rmse: 0.261552\tTest's rmse: 0.261122\n",
      "[100]\tTrain's rmse: 0.216195\tTest's rmse: 0.226674\n",
      "[150]\tTrain's rmse: 0.201843\tTest's rmse: 0.216828\n",
      "[200]\tTrain's rmse: 0.192666\tTest's rmse: 0.210659\n",
      "[250]\tTrain's rmse: 0.185401\tTest's rmse: 0.206016\n",
      "[300]\tTrain's rmse: 0.179886\tTest's rmse: 0.202986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[350]\tTrain's rmse: 0.17522\tTest's rmse: 0.200459\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tTrain's rmse: 0.171138\tTest's rmse: 0.198466\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[450]\tTrain's rmse: 0.167489\tTest's rmse: 0.196694\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\tTrain's rmse: 0.164018\tTest's rmse: 0.195001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[550]\tTrain's rmse: 0.160945\tTest's rmse: 0.193618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tTrain's rmse: 0.158337\tTest's rmse: 0.192472\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[650]\tTrain's rmse: 0.155601\tTest's rmse: 0.191397\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tTrain's rmse: 0.152843\tTest's rmse: 0.190199\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[750]\tTrain's rmse: 0.150339\tTest's rmse: 0.189351\n",
      "[800]\tTrain's rmse: 0.14795\tTest's rmse: 0.188377\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\tTrain's rmse: 0.145606\tTest's rmse: 0.18738\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tTrain's rmse: 0.143244\tTest's rmse: 0.186403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[950]\tTrain's rmse: 0.141087\tTest's rmse: 0.185413\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tTrain's rmse: 0.139076\tTest's rmse: 0.184596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tTrain's rmse: 0.139099\tTest's rmse: 0.184595\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear dataset LightGBM\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# Parmetros\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 10,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Diccionario donde se guardarn las mtricas\n",
    "evals_result = {}\n",
    "\n",
    "# Entrenar con early stopping + registro de mtricas\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgb_train, lgb_eval],\n",
    "    valid_names=['Train','Test'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=50),\n",
    "        lgb.record_evaluation(evals_result)  # <-- registra mtricas aqu\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Graficar curva de aprendizaje desde evals_result\n",
    "lgb.plot_metric(evals_result, metric='rmse')\n",
    "plt.title(\"Curva de aprendizaje LightGBM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93849071",
   "metadata": {},
   "source": [
    "Forma general:\n",
    "- Tanto Train como Test parten con un RMSE cercano a 0.7 y caen muy rpido en las primeras ~100 iteraciones.\n",
    "- A partir de ah, la mejora es cada vez ms lenta y ambas curvas se aplanan progresivamente.\n",
    "- La curva de Train sigue descendiendo hasta ~0.13, mientras que la de Test se estabiliza alrededor de ~0.180.19.\n",
    "\n",
    "Generalizacin y sobreajuste:\n",
    "- La brecha TrainTest es clara: Train mejora continuamente. Test mejora hasta ~200300 iteraciones y luego se aplana, sin subir.\n",
    "- Esto indica un sobreajuste moderado: el modelo sigue aprendiendo patrones en entrenamiento que ya no benefician a Test, aunque por suerte no empeora el desempeo en Test.\n",
    "\n",
    "Punto ptimo:\n",
    "- El punto de saturacin parece estar alrededor de las 200300 iteraciones (similar al caso con XGBoost).\n",
    "- Entrenar hasta 1000 iteraciones no aporta mejoras significativas en Test, aunque s reduce RMSE en Train.\n",
    "\n",
    "Comparacin con XGBoost:\n",
    "- La forma de ambas curvas (XGBoost y LightGBM) es prcticamente la misma: cada rpida inicial, luego meseta.\n",
    "- La diferencia principal suele ser que LightGBM entrena ms rpido y escala mejor con grandes datasets, aunque el comportamiento de las curvas sea casi idntico.\n",
    "\n",
    "Recomendaciones prcticas:\n",
    "- Usar early stopping para que el entrenamiento se corte alrededor de 200300 rboles.\n",
    "- Ajustar hiperparmetros de regularizacin (min_child_samples, lambda_l1, lambda_l2, feature_fraction) si quers reducir un poco ms la brecha TrainTest.\n",
    "- Si el RMSE en Test ya es suficientemente bueno, lo ms importante es no entrenar de ms y ahorrar tiempo.\n",
    "\n",
    "Conclusion:\n",
    "- Tu modelo con LightGBM generaliza bien, el Test se estabiliza pronto sin empeorar, y no tiene sobreajuste fuerte.\n",
    "- El punto ptimo est entre 200 y 300 iteraciones. Ms all de eso, solo mejoras en Train, pero sin beneficio en Test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
